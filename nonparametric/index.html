<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Non-Parametric Tests · Pingouin</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">Pingouin</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Pingouin.jl Documentation</a></li><li><a class="tocitem" href="../datasets/">Datasets</a></li><li><a class="tocitem" href="../distributions/">Distributions</a></li><li><a class="tocitem" href="../effsize/">Effect Sizes</a></li><li><a class="tocitem" href="../bayesian/">Bayesian</a></li><li class="is-active"><a class="tocitem" href>Non-Parametric Tests</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Non-Parametric Tests</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Non-Parametric Tests</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/clementpoiret/Pingouin.jl/blob/master/docs/src/nonparametric.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Non-parametric-tests"><a class="docs-heading-anchor" href="#Non-parametric-tests">Non-parametric tests</a><a id="Non-parametric-tests-1"></a><a class="docs-heading-anchor-permalink" href="#Non-parametric-tests" title="Permalink"></a></h1><p>Multiple non-parametric tests. Here, Pingouin is mostly a wrapper around <code>HypothesisTests.jl</code>.</p><article class="docstring"><header><a class="docstring-binding" id="Pingouin.cochran-Tuple{DataFrames.DataFrame}" href="#Pingouin.cochran-Tuple{DataFrames.DataFrame}"><code>Pingouin.cochran</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cochran(data[, dv, within, subject])</code></pre><p>Cochran Q test. A special case of the Friedman test when the dependent variable is binary.</p><p><strong>Arguments</strong></p><ul><li><code>data::DataFrame</code></li><li><code>dv::Union{Nothing,String,Symbol}</code>: Name of column containing the binary dependent variable.</li><li><code>within::Union{Nothing,String,Symbol}</code>: Name of column containing the within-subject factor.</li><li><code>subject::Union{Nothing,String,Symbol}</code>: Name of column containing the subject identifier.</li></ul><p><strong>Returns</strong></p><ul><li><code>stats::DataFrame</code><ul><li><code>&#39;Q&#39;</code>: The Cochran Q statistic,</li><li><code>&#39;p-unc&#39;</code>: Uncorrected p-value,</li><li><code>&#39;ddof&#39;</code>: degrees of freedom.</li></ul></li></ul><p><strong>Notes</strong></p><p>The Cochran Q test [1] is a non-parametric test for ANOVA with repeated measures where the dependent variable is binary.</p><p>Data are expected to be in long-format. NaN are automatically removed from the data.</p><p>The Q statistics is defined as:</p><p class="math-container">\[Q = \frac{(r-1)(r\sum_j^rx_j^2-N^2)}{rN-\sum_i^nx_i^2}\]</p><p>where <span>$N$</span> is the total sum of all observations, <span>$j=1,...,r$</span> where <span>$r$</span> is the number of repeated measures, <span>$i=1,...,n$</span> where <span>$n$</span> is the number of observations per condition.</p><p>The p-value is then approximated using a chi-square distribution with <span>$r-1$</span> degrees of freedom:</p><p class="math-container">\[Q \sim \chi^2(r-1)\]</p><p><strong>References</strong></p><p>[1] Cochran, W.G., 1950. The comparison of percentages in matched samples. Biometrika 37, 256–266. https://doi.org/10.1093/biomet/37.3-4.256</p><p><strong>Examples</strong></p><p>Compute the Cochran Q test for repeated measurements.</p><pre><code class="language-julia-repl">julia&gt; data = Pingouin.read_dataset(&quot;cochran&quot;);
julia&gt; cochran(data, dv=&quot;Energetic&quot;, within=&quot;Time&quot;, subject=&quot;Subject&quot;)
1×4 DataFrame
│ Row │ Source │ ddof  │ Q       │ p_unc     │
│     │ String │ Int64 │ Float64 │ Float64   │
├─────┼────────┼───────┼─────────┼───────────┤
│ 1   │ Time   │ 2     │ 6.70588 │ 0.0349813 │</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/f0c1467bf2447643b821f24c6ff36e373cedcd60/src/nonparametric.jl#L396-L456">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.friedman-Tuple{DataFrames.DataFrame}" href="#Pingouin.friedman-Tuple{DataFrames.DataFrame}"><code>Pingouin.friedman</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">friedman(data, dv, within, subject, method)</code></pre><p>Friedman test for repeated measurements.</p><p><strong>Arguments</strong></p><ul><li><code>data::DataFrame</code>,</li><li><code>dv::Union{String,Symbol}</code>: Name of column containing the dependent variable,</li><li><code>within::Union{String,Symbol}</code>: Name of column containing the within-subject factor,</li><li><code>subject::Union{String,Symbol}</code>: Name of column containing the subject identifier,</li><li><code>method::String</code>: Statistical test to perform. Must be <code>&quot;chisq&quot;</code> (chi-square test) or <code>&quot;f&quot;</code> (F test).</li></ul><p>See notes below for explanation.</p><p><strong>Returns</strong></p><ul><li><code>&quot;W&quot;</code>: Kendall&#39;s coefficient of concordance, corrected for ties,</li><li><code>stats::DataFrame</code>, if <code>method=&quot;chisq&quot;</code><ul><li><code>&quot;Q&quot;</code>: The Friedman Q statistic, corrected for ties,</li><li><code>&quot;p-unc&quot;</code>: Uncorrected p-value,</li><li><code>&quot;ddof&quot;</code>: degrees of freedom.</li></ul></li><li><code>stats::DataFrame</code>, if <code>method=&quot;f&quot;</code>:<ul><li><code>&quot;F&quot;</code>: The Friedman F statistic, corrected for ties,</li><li><code>&quot;p-unc&quot;</code>: Uncorrected p-value,</li><li><code>&quot;ddof1&quot;</code>: degrees of freedom of the numerator,</li><li><code>&quot;ddof2&quot;</code>: degrees of freedom of the denominator.</li></ul></li></ul><p><strong>Notes</strong></p><p>The Friedman test is used for one-way repeated measures ANOVA by ranks.</p><p>Data are expected to be in long-format.</p><p>Note that if the dataset contains one or more other within subject factors, an automatic collapsing to the mean is applied on the dependent variable (same behavior as the ezANOVA R package). As such, results can differ from those of JASP. If you can, always double-check the results.</p><p>Due to the assumption that the test statistic has a chi squared distribution, the p-value is only reliable for n &gt; 10 and more than 6 repeated measurements.</p><p>NaN values are automatically removed.</p><p>The Friedman test is equivalent to the test of significance of Kendalls&#39;s coefficient of concordance (Kendall&#39;s W). Most commonly a Q statistic, which has asymptotical chi-squared distribution, is computed and used for testing. However, in [1] they showed the chi-squared test to be overly conservative for small numbers of samples and repeated measures. Instead they recommend the F test, which has the correct size and behaves like a permutation test, but is computationaly much easier.</p><p><strong>References</strong></p><p>[1] Marozzi, M. (2014). Testing for concordance between several     criteria. Journal of Statistical Computation and Simulation,     84(9), 1843–1850. https://doi.org/10.1080/00949655.2013.766189</p><p><strong>Examples</strong></p><p>Compute the Friedman test for repeated measurements.</p><pre><code class="language-julia-repl">julia&gt; data = Pingouin.read_dataset(&quot;rm_anova&quot;)
julia&gt; Pingouin.friedman(data,
                         dv=&quot;DesireToKill&quot;,
                         within=&quot;Disgustingness&quot;,
                         subject=&quot;Subject&quot;)
1×5 DataFrame
 Row │ Source          W          ddof   Q        p_unc      
     │ String          Float64    Int64  Float64  Float64    
─────┼───────────────────────────────────────────────────────
   1 │ Disgustingness  0.0992242      1  9.22785  0.00238362</code></pre><p>This time we will use the F test method.</p><pre><code class="language-julia-repl">julia&gt; data = Pingouin.read_dataset(&quot;rm_anova&quot;)
julia&gt; Pingouin.friedman(data,
                         dv=&quot;DesireToKill&quot;,
                         within=&quot;Disgustingness&quot;,
                         subject=&quot;Subject&quot;,
                         method=&quot;f&quot;)
1×6 DataFrame
 Row │ Source          W          ddof1     ddof2    F        p_unc      
     │ String          Float64    Float64   Float64  Float64  Float64    
─────┼───────────────────────────────────────────────────────────────────
   1 │ Disgustingness  0.0992242  0.978495  90.0215  10.1342  0.00213772</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/f0c1467bf2447643b821f24c6ff36e373cedcd60/src/nonparametric.jl#L635-L727">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.harrelldavis" href="#Pingouin.harrelldavis"><code>Pingouin.harrelldavis</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">harrelldavis(x[, q, dim])</code></pre><p><em>EXPERIMENTAL</em> Harrell-Davis robust estimate of the <span>$q^{th}$</span> quantile(s) of the data. <em>TESTS NEEDED</em></p><p><strong>Arguments</strong></p><ul><li><code>x::Array{&lt;:Number}</code>: Data, must be a one or two-dimensional vector.</li><li><code>q::Union{Float64,Array{Float64}}</code>: Quantile or sequence of quantiles to compute, must be between 0 and 1. Default is <span>$0.5$</span>.</li><li><code>dim::Int64</code>: Axis along which the MAD is computed. Default is the first axis. Can be either 1 or 2.</li></ul><p><strong>Returns</strong></p><ul><li><code>y::Union{Float64,Array{Float64}}</code>: The estimated quantile(s). If <code>quantile</code> is a single quantile, will return a float, otherwise will compute each quantile separately and returns an array of floats.</li></ul><p><strong>Notes</strong></p><p>The Harrell-Davis method [1] estimates the <span>$q^{th}$</span> quantile by a linear combination of  the  order statistics. Results have been tested against a Matlab implementation [2]. Note that this method is also used to measure the confidence intervals of the difference between quantiles of two groups, as implemented in the shift function [3].</p><p><strong>See Also</strong></p><p><a href="@ref"><code>plot_shift</code></a></p><p><strong>References</strong></p><p>[1] Frank E. Harrell, C. E. Davis, A new distribution-free quantile estimator, Biometrika, Volume 69, Issue 3, December 1982, Pages 635–640, https://doi.org/10.1093/biomet/69.3.635</p><p>[2] https://github.com/GRousselet/matlab_stats/blob/master/hd.m</p><p>[3] Rousselet, G. A., Pernet, C. R. and Wilcox, R. R. (2017). Beyond differences in means: robust graphical methods to compare two groups in neuroscience. Eur J Neurosci, 46: 1738-1748. https://doi.org/doi:10.1111/ejn.13610</p><p><strong>Examples</strong></p><p>Estimate the 0.5 quantile (i.e median) of 100 observation picked from a normal distribution with zero mean and unit variance.</p><pre><code class="language-julia-repl">julia&gt; using Distributions, Random
julia&gt; d = Normal(0, 1)
julia&gt; x = rand(d, 100);
&gt;&gt;&gt; Pingouin.harrelldavis(x, 0.5)
-0.3197175569523778</code></pre><p>Several quantiles at once</p><pre><code class="language-julia-repl">julia&gt; Pingouin.harrelldavis(x, [0.25, 0.5, 0.75])
3-element Array{Float64,1}:
 -0.8584761447019648
 -0.3197175569523778
  0.30049291160713604</code></pre><p>On the last axis of a 2D vector (default)</p><pre><code class="language-julia-repl">julia&gt; using Distributions, Random
julia&gt; d = Normal(0, 1)
julia&gt; x = rand(d, (100, 100));
julia&gt; Pingouin.harrelldavis(x, 0.5)
100×1 Array{Float64,2}:
  0.08776830864191214
  0.03470963005927001
 -0.0805646920967012
  0.3314919956251108
  0.3111971350475172
  ⋮
  0.10769293112437549
 -0.10622118136247076
 -0.13230506142402296
 -0.09693123033727057
 -0.2135938540892071</code></pre><p>On the first axis</p><pre><code class="language-julia-repl">julia&gt; Pingouin.harrelldavis(x, 0.5, 1)
1×100 Array{Float64,2}:
 0.0112259  -0.0409635  -0.0918462 ...</code></pre><p>On the first axis with multiple quantiles</p><pre><code class="language-julia-repl">julia&gt; Pingouin.harrelldavis(x, [0.5, 0.75], 1)
1×100 Array{Float64,2}:
 0.0112259  -0.0409635  -0.0918462 ...</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/f0c1467bf2447643b821f24c6ff36e373cedcd60/src/nonparametric.jl#L478-L579">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.kruskal-Tuple{Any}" href="#Pingouin.kruskal-Tuple{Any}"><code>Pingouin.kruskal</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">kruskal(data[, dv, between, detailed])</code></pre><p>Kruskal-Wallis H-test for independent samples.</p><p><strong>Arguments</strong></p><ul><li><code>data::DataFrame</code>: DataFrame,</li><li><code>dv::String</code>: Name of column containing the dependent variable,</li><li><code>between::String</code>: Name of column containing the between factor.</li></ul><p><strong>Returns</strong></p><ul><li><code>stats::DataFrame</code><ul><li><code>&#39;H&#39;</code>: The Kruskal-Wallis H statistic, corrected for ties,</li><li><code>&#39;p-unc&#39;</code>: Uncorrected p-value,</li><li><code>&#39;dof&#39;</code>: degrees of freedom.</li></ul></li></ul><p><strong>Notes</strong></p><p>The Kruskal-Wallis H-test tests the null hypothesis that the population median of all of the groups are equal. It is a non-parametric version of ANOVA. The test works on 2 or more independent samples, which may have different sizes.</p><p>Due to the assumption that H has a chi square distribution, the number of samples in each group must not be too small. A typical rule is that each sample must have at least 5 measurements.</p><p>NaN values are automatically removed.</p><p><strong>Examples</strong></p><p>Compute the Kruskal-Wallis H-test for independent samples.</p><pre><code class="language-julia-repl">julia&gt; data = Pingouin.read_dataset(&quot;anova&quot;)
julia&gt; Pingouin.kruskal(data, dv=&quot;Pain threshold&quot;, between=&quot;Hair color&quot;)
1×4 DataFrame
│ Row │ Source     │ ddof  │ H       │ p_unc     │
│     │ String     │ Int64 │ Float64 │ Float64   │
├─────┼────────────┼───────┼─────────┼───────────┤
│ 1   │ Hair color │ 3     │ 10.5886 │ 0.0141716 │</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/f0c1467bf2447643b821f24c6ff36e373cedcd60/src/nonparametric.jl#L330-L374">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.madmedianrule-Tuple{Array{var&quot;#s176&quot;,N} where N where var&quot;#s176&quot;&lt;:Number}" href="#Pingouin.madmedianrule-Tuple{Array{var&quot;#s176&quot;,N} where N where var&quot;#s176&quot;&lt;:Number}"><code>Pingouin.madmedianrule</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">madmedianrule(a)</code></pre><p>Robust outlier detection based on the MAD-median rule.</p><p><strong>Arguments</strong></p><ul><li><code>a::Array{&lt;:Number}</code>: Input array. Must be one-dimensional.</li></ul><p><strong>Returns</strong></p><ul><li><code>outliers::Array{Bool}</code>: Boolean array indicating whether each sample is an outlier (true) or not (false).</li></ul><p><strong>See also</strong></p><p><code>Statistics.mad</code></p><p><strong>Notes</strong></p><p>The MAD-median-rule ([1], [2]) will refer to declaring <span>$X_i$</span> an outlier if</p><p class="math-container">\[\frac{\left | X_i - M \right |}{\text{MAD}_{\text{norm}}} &gt; K\]</p><p>,</p><p>where <span>$M$</span> is the median of <span>$X$</span>, <span>$\text{MAD}_{\text{norm}}$</span> the normalized median absolute deviation of <span>$X$</span>, and <span>$K$</span> is the square root of the .975 quantile of a <span>$X^2$</span> distribution with one degree of freedom, which is roughly equal to 2.24.</p><p><strong>References</strong></p><p>[1] Hall, P., Welsh, A.H., 1985. Limit theorems for the median deviation. Ann. Inst. Stat. Math. 37, 27–36. https://doi.org/10.1007/BF02481078</p><p>[2] Wilcox, R. R. Introduction to Robust Estimation and Hypothesis Testing. (Academic Press, 2011).</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; a = [-1.09, 1., 0.28, -1.51, -0.58, 6.61, -2.43, -0.43]
julia&gt; Pingouin.madmedianrule(a)
8-element Array{Bool,1}:
 0
 0
 0
 0
 0
 1
 0
 0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/f0c1467bf2447643b821f24c6ff36e373cedcd60/src/nonparametric.jl#L8-L62">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.mwu-Tuple{Array{var&quot;#s175&quot;,N} where N where var&quot;#s175&quot;&lt;:Number,Array{var&quot;#s174&quot;,N} where N where var&quot;#s174&quot;&lt;:Number}" href="#Pingouin.mwu-Tuple{Array{var&quot;#s175&quot;,N} where N where var&quot;#s175&quot;&lt;:Number,Array{var&quot;#s174&quot;,N} where N where var&quot;#s174&quot;&lt;:Number}"><code>Pingouin.mwu</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mwu(x, y)</code></pre><p>Mann-Whitney U Test (= Wilcoxon rank-sum test). It is the non-parametric version of the independent T-test.</p><p><strong>Arguments</strong></p><ul><li><code>x, y::Array{&lt;:Number}</code>: First and second set of observations. <code>x</code> and <code>y</code> must be independent.</li></ul><p><strong>Returns</strong></p><ul><li><code>stats::DataFrame</code><ul><li><code>&#39;U-val&#39;</code>: U-value</li><li><code>&#39;p-val&#39;</code>: p-value</li><li><code>&#39;RBC&#39;</code>: rank-biserial correlation</li><li><code>&#39;CLES&#39;</code>: common language effect size</li></ul></li></ul><p><strong>See also</strong></p><ul><li><code>HypothesisTests.MannWhitneyUTest</code>,</li><li><a href="#Pingouin.wilcoxon-Tuple{Array{var&quot;#s175&quot;,N} where N where var&quot;#s175&quot;&lt;:Number,Array{var&quot;#s174&quot;,N} where N where var&quot;#s174&quot;&lt;:Number}"><code>wilcoxon</code></a>,</li><li><a href="@ref"><code>ttest</code></a>.</li></ul><p><strong>Notes</strong></p><p>The Mann–Whitney U test [1], (also called Wilcoxon rank-sum test) is a non-parametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. The test assumes that the two samples are independent. This test corrects for ties and by default uses a continuity correction (see <code>HypothesisTests.MannWhitneyUTest</code> for details).</p><p>The rank biserial correlation [2] is the difference between the proportion of favorable evidence minus the proportion of unfavorable evidence.</p><p>The common language effect size is the proportion of pairs where <span>$x$</span> is higher than <span>$y$</span>. It was first introduced by McGraw and Wong (1992) [3]. Pingouin uses a brute-force version of the formula given by Vargha and Delaney 2000 [4]:</p><p class="math-container">\[\text{CL} = P(X &gt; Y) + .5 \times P(X = Y)\]</p><p>The advantage is of this method are twofold. First, the brute-force approach pairs each observation of <span>$x$</span> to its <span>$y$</span> counterpart, and therefore does not require normally distributed data. Second, the formula takes ties into account and therefore works with ordinal data.</p><p><strong>References</strong></p><p>[1] Mann, H. B., &amp; Whitney, D. R. (1947). On a test of whether one of two random variables is stochastically larger than the other. The annals of mathematical statistics, 50-60.</p><p>[2] Kerby, D. S. (2014). The simple difference formula: An approach to teaching nonparametric correlation. Comprehensive Psychology, 3, 11-IT.</p><p>[3] McGraw, K. O., &amp; Wong, S. P. (1992). A common language effect size statistic. Psychological bulletin, 111(2), 361.</p><p>[4] Vargha, A., &amp; Delaney, H. D. (2000). A Critique and Improvement of the “CL” Common Language Effect Size Statistics of McGraw and Wong. Journal of Educational and Behavioral Statistics: A Quarterly Publication Sponsored by the American Educational Research Association and the American Statistical Association, 25(2), 101–132. https://doi.org/10.2307/1165329</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; x = [1,4,2,5,3,6,9,8,7]
julia&gt; y = [2,4,1,5,10,1,4,9,8,5]
julia&gt; Pingouin.mwu(x, y)
1×4 DataFrame
│ Row │ U_val   │ p_val    │ RBC        │ CLES     │
│     │ Float64 │ Float64  │ Float64    │ Float64  │
├─────┼─────────┼──────────┼────────────┼──────────┤
│ 1   │ 46.5    │ 0.934494 │ -0.0333333 │ 0.516667 │</code></pre><p>Compare with HypothesisTests</p><pre><code class="language-julia-repl">julia&gt; using HypothesisTests
julia&gt; MannWhitneyUTest(x, y)
Approximate Mann-Whitney U test
-------------------------------
Population details:
    parameter of interest:   Location parameter (pseudomedian)
    value under h_0:         0
    point estimate:          0.5

Test summary:
    outcome with 95% confidence: fail to reject h_0
    two-sided p-value:           0.9345

Details:
    number of observations in each group: [9, 10]
    Mann-Whitney-U statistic:             46.5
    rank sums:                            [91.5, 98.5]
    adjustment for ties:                  90.0
    normal approximation (μ, σ):          (1.5, 12.1666)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/f0c1467bf2447643b821f24c6ff36e373cedcd60/src/nonparametric.jl#L70-L176">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.wilcoxon-Tuple{Array{var&quot;#s175&quot;,N} where N where var&quot;#s175&quot;&lt;:Number,Array{var&quot;#s174&quot;,N} where N where var&quot;#s174&quot;&lt;:Number}" href="#Pingouin.wilcoxon-Tuple{Array{var&quot;#s175&quot;,N} where N where var&quot;#s175&quot;&lt;:Number,Array{var&quot;#s174&quot;,N} where N where var&quot;#s174&quot;&lt;:Number}"><code>Pingouin.wilcoxon</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">wilcoxon(x, y)</code></pre><p>Wilcoxon signed-rank test. It is the non-parametric version of the paired T-test.</p><p><strong>Arguments</strong></p><ul><li><code>x, y::Array{&lt;:Number}</code>: First and second set of observations. <span>$x$</span> and <span>$y$</span> must be related (e.g repeated measures) and, therefore, have the same number of samples. Note that a listwise deletion of missing values is automatically applied.</li></ul><p><strong>Returns</strong></p><ul><li><code>stats::DataFrame</code><ul><li><code>&#39;W-val&#39;</code>: W-value</li><li><code>&#39;p-val&#39;</code>: p-value</li><li><code>&#39;RBC&#39;</code>: matched pairs rank-biserial correlation (effect size)</li><li><code>&#39;CLES&#39;</code>: common language effect size</li></ul></li></ul><p><strong>See also</strong></p><ul><li><code>HypothesisTests.SignedRankTest</code>,</li><li><a href="#Pingouin.mwu-Tuple{Array{var&quot;#s175&quot;,N} where N where var&quot;#s175&quot;&lt;:Number,Array{var&quot;#s174&quot;,N} where N where var&quot;#s174&quot;&lt;:Number}"><code>mwu</code></a>.</li></ul><p><strong>Notes</strong></p><p>The Wilcoxon signed-rank test [1] tests the null hypothesis that two related paired samples come from the same distribution. In particular, it tests whether the distribution of the differences <span>$x - y$</span> is symmetric about zero. A continuity correction is applied by default (see <code>HypothesisTests.SignedRankTest</code> for details).</p><p>The matched pairs rank biserial correlation [2] is the simple difference between the proportion of favorable and unfavorable evidence; in the case of the Wilcoxon signed-rank test, the evidence consists of rank sums (Kerby 2014):</p><p class="math-container">\[r = f - u\]</p><p>The common language effect size is the proportion of pairs where <span>$x$</span> is higher than <span>$y$</span>. It was first introduced by McGraw and Wong (1992) [3]. Pingouin uses a brute-force version of the formula given by Vargha and Delaney 2000 [4]:</p><p class="math-container">\[\text{CL} = P(X &gt; Y) + .5 \times P(X = Y)\]</p><p>The advantage is of this method are twofold. First, the brute-force approach pairs each observation of <span>$x$</span> to its <span>$y$</span> counterpart, and therefore does not require normally distributed data. Second, the formula takes ties into account and therefore works with ordinal data.</p><p><strong>References</strong></p><p>[1] Wilcoxon, F. (1945). Individual comparisons by ranking methods. Biometrics bulletin, 1(6), 80-83.</p><p>[2] Kerby, D. S. (2014). The simple difference formula: An approach to teaching nonparametric correlation. Comprehensive Psychology, 3, 11-IT.</p><p>[3] McGraw, K. O., &amp; Wong, S. P. (1992). A common language effect size statistic. Psychological bulletin, 111(2), 361.</p><p>[4] Vargha, A., &amp; Delaney, H. D. (2000). A Critique and Improvement of the “CL” Common Language Effect Size Statistics of McGraw and Wong. Journal of Educational and Behavioral Statistics: A Quarterly Publication Sponsored by the American Educational Research Association and the American Statistical Association, 25(2), 101–132. https://doi.org/10.2307/1165329</p><p><strong>Examples</strong></p><p>Wilcoxon test on two related samples.</p><pre><code class="language-julia-repl">julia&gt; x = [20, 22, 19, 20, 22, 18, 24, 20, 19, 24, 26, 13]
julia&gt; y = [38, 37, 33, 29, 14, 12, 20, 22, 17, 25, 26, 16]
julia&gt; Pingouin.wilcoxon(x, y)
1×4 DataFrame
│ Row │ W_val   │ p_val    │ RBC       │ CLES     │
│     │ Float64 │ Float64  │ Float64   │ Float64  │
├─────┼─────────┼──────────┼───────────┼──────────┤
│ 1   │ 20.5    │ 0.288086 │ -0.378788 │ 0.395833 │</code></pre><p>Compare with HypothesisTests</p><pre><code class="language-julia-repl">julia&gt; using HypothesisTests
julia&gt; SignedRankTest(x, y)
Exact Wilcoxon signed rank test
-------------------------------
Population details:
    parameter of interest:   Location parameter (pseudomedian)
    value under h_0:         0
    point estimate:          -1.5
    95% confidence interval: (-9.0, 2.5)

Test summary:
    outcome with 95% confidence: fail to reject h_0
    two-sided p-value:           0.2881

Details:
    number of observations:      12
    Wilcoxon rank-sum statistic: 20.5
    rank sums:                   [20.5, 45.5]
    adjustment for ties:         6.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/f0c1467bf2447643b821f24c6ff36e373cedcd60/src/nonparametric.jl#L200-L307">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../bayesian/">« Bayesian</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Saturday 13 February 2021 19:20">Saturday 13 February 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
