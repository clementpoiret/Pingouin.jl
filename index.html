<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Pingouin.jl · Pingouin</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">Pingouin</span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Pingouin.jl</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Pingouin.jl</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Pingouin.jl</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/clementpoiret/Pingouin.jl/blob/master/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Pingouin.jl"><a class="docs-heading-anchor" href="#Pingouin.jl">Pingouin.jl</a><a id="Pingouin.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Pingouin.jl" title="Permalink"></a></h1><p>Documentation for Pingouin.jl</p><article class="docstring"><header><a class="docstring-binding" id="Pingouin.list_dataset-Tuple{}" href="#Pingouin.list_dataset-Tuple{}"><code>Pingouin.list_dataset</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">list_dataset()</code></pre><p>List available example datasets.</p><p><strong>Returns</strong></p><ul><li>datasets : <code>DataFrame</code>: A dataframe with the name, description and reference of all the datasets included in Pingouin.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; all_datasets = Pingouin.list_dataset()
28×4 DataFrame. Omitted printing of 1 columns
│ Row │ dataset    │ description                                                                                                        │ useful                 │
│     │ String     │ String                                                                                                             │ String                 │
├─────┼────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────┤
│ 1   │ ancova     │ Teaching method with family income as covariate                                                                    │ ANCOVA                 │
│ 2   │ anova      │ Pain threshold per hair color                                                                                      │ anova - pairwise_tukey │
│ 3   │ anova2     │ Fertilizer impact on the yield of crops                                                                            │ anova                  │
⋮
│ 25  │ rm_anova2  │ Performance of employees at two time points and three areas                                                        │ rm_anova2              │
│ 26  │ rm_corr    │ Repeated measurements of pH and PaCO2                                                                              │ rm_corr                │
│ 27  │ rm_missing │ Missing values in long-format repeated measures dataframe                                                          │ rm_anova - rm_anova2   │
│ 28  │ tips       │ One waiter recorded information about each tip he received over a period of a few months working in one restaurant │ regression             │</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/datasets.jl#L48-L74">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.read_dataset-Tuple{String}" href="#Pingouin.read_dataset-Tuple{String}"><code>Pingouin.read_dataset</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">read_dataset(dname)</code></pre><p>Read example datasets.</p><p><strong>Arguments</strong></p><ul><li><code>dname::String</code>: Name of dataset to read (without extension). Must be a valid dataset present in Pingouin.datasets</li></ul><p><strong>Returns</strong></p><ul><li>data : <code>DataFrame</code>: Requested dataset.</li></ul><p><strong>Examples</strong></p><p>Load the <code>Penguin &lt;https://github.com/allisonhorst/palmerpenguins&gt;</code> dataset:</p><pre><code class="language-julia-repl">julia&gt; data = Pingouin.read_dataset(&quot;penguins&quot;)
344×7 DataFrame
│ Row │ species │ island │ bill_length_mm │ bill_depth_mm │ flipper_length_mm │ body_mass_g │ sex    │
│     │ String  │ String │ String         │ String        │ String            │ String      │ String │
├─────┼─────────┼────────┼────────────────┼───────────────┼───────────────────┼─────────────┼────────┤
│ 1   │ Adelie  │ Biscoe │ 37.8           │ 18.3          │ 174               │ 3400        │ female │
│ 2   │ Adelie  │ Biscoe │ 37.7           │ 18.7          │ 180               │ 3600        │ male   │
│ 3   │ Adelie  │ Biscoe │ 35.9           │ 19.2          │ 189               │ 3800        │ female │
⋮
│ 341 │ Gentoo  │ Biscoe │ 46.8           │ 14.3          │ 215               │ 4850        │ female │
│ 342 │ Gentoo  │ Biscoe │ 50.4           │ 15.7          │ 222               │ 5750        │ male   │
│ 343 │ Gentoo  │ Biscoe │ 45.2           │ 14.8          │ 212               │ 5200        │ female │
│ 344 │ Gentoo  │ Biscoe │ 49.9           │ 16.1          │ 213               │ 5400        │ male   │</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/datasets.jl#L4-L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin._transform_rm-Tuple{DataFrames.DataFrame}" href="#Pingouin._transform_rm-Tuple{DataFrames.DataFrame}"><code>Pingouin._transform_rm</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Convert long-format dataframe (one and two-way designs). This internal function is used in Pingouin.epsilon and Pingouin.sphericity.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/distributions.jl#L925-L928">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.anderson-Tuple{Array{var&quot;#s31&quot;,N} where N where var&quot;#s31&quot;&lt;:Number}" href="#Pingouin.anderson-Tuple{Array{var&quot;#s31&quot;,N} where N where var&quot;#s31&quot;&lt;:Number}"><code>Pingouin.anderson</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">anderson(x[, dist])</code></pre><p>Anderson-Darling test of distribution.</p><p><strong>Arguments</strong></p><ul><li><code>x::Array{&lt;:Number}</code>: Array of sample data. May be different lengths,</li><li><code>dist::Union{String, Distribution}</code>: Distribution (&quot;norm&quot;, &quot;expon&quot;, &quot;logistic&quot;, &quot;gumbel&quot;).</li></ul><p><strong>Returns</strong></p><ul><li><code>H::Bool</code>: True if data comes from this distribution,</li><li><code>P::Float64</code>: The significance levels for the corresponding critical values in %.</li></ul><p>(See :<code>HypothesisTests.OneSampleADTest</code> for more details).</p><p><strong>Examples</strong></p><ol><li>Test that an array comes from a normal distribution</li></ol><pre><code class="language-julia-repl">julia&gt; x = [2.3, 5.1, 4.3, 2.6, 7.8, 9.2, 1.4]
julia&gt; Pingouin.anderson(x, dist=&quot;norm&quot;)
(false, 8.571428568870942e-5)</code></pre><ol><li>Test that an array comes from a custom distribution</li></ol><pre><code class="language-julia-repl">&gt; x = [2.3, 5.1, 4.3, 2.6, 7.8, 9.2, 1.4]
&gt; Pingouin.anderson(x, dist=Normal(1,5))
(false, 0.04755873570126501)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/distributions.jl#L70-L103">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.epsilon-Tuple{Union{DataFrames.DataFrame, Array{var&quot;#s30&quot;,N} where N where var&quot;#s30&quot;&lt;:Number}}" href="#Pingouin.epsilon-Tuple{Union{DataFrames.DataFrame, Array{var&quot;#s30&quot;,N} where N where var&quot;#s30&quot;&lt;:Number}}"><code>Pingouin.epsilon</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">epsilon(data[, dv, within, subject, correction])</code></pre><p>Epsilon adjustement factor for repeated measures.</p><p><strong>Arguments</strong></p><ul><li><code>data::Union{Array{&lt;:Number}, DataFrame}</code>: DataFrame containing the repeated measurements. Only long-format dataframe are supported for this function.</li><li><code>dv::Union{Symbol, String, Nothing}</code>: Name of column containing the dependent variable.</li><li><code>within::Union{Array{String}, Array{Symbol}, Symbol, String, Nothing}</code>: Name of column containing the within factor (only required if <code>data</code> is in long format). If <code>within</code> is a list with two strings, this function computes the epsilon factor for the interaction between the two within-subject factor.</li><li><code>subject::Union{Symbol, String, Nothing}</code>: Name of column containing the subject identifier (only required if <code>data</code> is in long format).</li><li><code>correction::String</code>: Specify the epsilon version:<ul><li><code>&quot;gg&quot;</code>: Greenhouse-Geisser,</li><li><code>&quot;hf&quot;</code>: Huynh-Feldt,</li><li><code>&quot;lb&quot;</code>: Lower bound.</li></ul></li></ul><p><strong>Returns</strong></p><p>eps::Float64: Epsilon adjustement factor.</p><p><strong>See Also</strong></p><ul><li><a href="#Pingouin.sphericity-Tuple{DataFrames.DataFrame}"><code>sphericity</code></a>: Mauchly and JNS test for sphericity.</li><li><a href="#Pingouin.homoscedasticity-Tuple{Any}"><code>homoscedasticity</code></a>: Test equality of variance.</li></ul><p><strong>Notes</strong></p><p>The lower bound epsilon is:</p><div>\[lb = \frac{1}{\text{dof}}\]</div><p>,</p><p>where the degrees of freedom <span>$\text{dof}$</span> is the number of groups <span>$k$</span> minus 1 for one-way design and <span>$(k_1 - 1)(k_2 - 1)$</span> for two-way design</p><p>The Greenhouse-Geisser epsilon is given by:</p><div>\[\epsilon_{GG} = \frac{k^2(\overline{\text{diag}(S)} - \overline{S})^2}{(k-1)(\sum_{i=1}^{k}\sum_{j=1}^{k}s_{ij}^2 - 2k\sum_{j=1}^{k}\overline{s_i}^2 + k^2\overline{S}^2)}\]</div><p>where <span>$S$</span> is the covariance matrix, <span>$\overline{S}$</span> the grandmean of S and <span>$\overline{\text{diag}(S)}$</span> the mean of all the elements on the diagonal of S (i.e. mean of the variances).</p><p>The Huynh-Feldt epsilon is given by:</p><div>\[\epsilon_{HF} = \frac{n(k-1)\epsilon_{GG}-2}{(k-1) (n-1-(k-1)\epsilon_{GG})}\]</div><p>where <span>$n$</span> is the number of observations.</p><p>Missing values are automatically removed from data (listwise deletion).</p><p><strong>Examples</strong></p><p>Using a wide-format dataframe</p><pre><code class="language-julia-repl">julia&gt; data = DataFrame(A = [2.2, 3.1, 4.3, 4.1, 7.2],
                     B = [1.1, 2.5, 4.1, 5.2, 6.4],
                     C = [8.2, 4.5, 3.4, 6.2, 7.2])
julia&gt; Pingouin.epsilon(data, correction=&quot;gg&quot;)
0.5587754577585018
julia&gt; Pingouin.epsilon(data, correction=&quot;hf&quot;)
0.6223448311539789
julia&gt; Pingouin.epsilon(data, correction=&quot;lb&quot;)
0.5</code></pre><p>Now using a long-format dataframe</p><pre><code class="language-julia-repl">julia&gt; data = Pingouin.read_dataset(&quot;rm_anova2&quot;)
julia&gt; head(data)
6×4 DataFrame
│ Row │ Subject │ Time   │ Metric  │ Performance │
│     │ Int64   │ String │ String  │ Int64       │
├─────┼─────────┼────────┼─────────┼─────────────┤
│ 1   │ 1       │ Pre    │ Product │ 13          │
│ 2   │ 2       │ Pre    │ Product │ 12          │
│ 3   │ 3       │ Pre    │ Product │ 17          │
│ 4   │ 4       │ Pre    │ Product │ 12          │
│ 5   │ 5       │ Pre    │ Product │ 19          │
│ 6   │ 6       │ Pre    │ Product │ 6           │</code></pre><p>Let&#39;s first calculate the epsilon of the <em>Time</em> within-subject factor</p><pre><code class="language-julia-repl">julia&gt; Pingouin.epsilon(data, dv=&quot;Performance&quot;, subject=&quot;Subject&quot;,
                     within=&quot;Time&quot;)
1.0</code></pre><p>Since <em>Time</em> has only two levels (Pre and Post), the sphericity assumption is necessarily met, and therefore the epsilon adjustement factor is 1.</p><p>The <em>Metric</em> factor, however, has three levels:</p><pre><code class="language-julia-repl">julia&gt; Pingouin.epsilon(data, dv=:Performance, subject=:Subject,
                     within=[:Metric])
0.9691029584899762</code></pre><p>The epsilon value is very close to 1, meaning that there is no major violation of sphericity.</p><p>Now, let&#39;s calculate the epsilon for the interaction between the two repeated measures factor:</p><pre><code class="language-julia-repl">julia&gt; Pingouin.epsilon(data, dv=:Performance, subject=:Subject,
                     within=[:Time, :Metric])
0.727166420214127</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/distributions.jl#L749-L863">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.gzscore-Tuple{Array{var&quot;#s33&quot;,N} where N where var&quot;#s33&quot;&lt;:Number}" href="#Pingouin.gzscore-Tuple{Array{var&quot;#s33&quot;,N} where N where var&quot;#s33&quot;&lt;:Number}"><code>Pingouin.gzscore</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">gzscore(x)</code></pre><p>Geometric standard (Z) score.</p><p><strong>Arguments</strong></p><ul><li><code>x::Array{&lt;:Number}</code>: Array of raw values</li></ul><p><strong>Returns</strong></p><ul><li><code>gzscore::Array{&lt;:Number}</code>: Array of geometric z-scores (same shape as x)</li></ul><p><strong>Notes</strong></p><p>Geometric Z-scores are better measures of dispersion than arithmetic z-scores when the sample data come from a log-normally distributed population [1].</p><p>Given the raw scores <span>$x$</span>, the geometric mean <span>$\mu_g$</span> and the geometric standard deviation <span>$\sigma_g$</span>, the standard score is given by the formula:</p><div>\[z = \frac{log(x) - log(\mu_g)}{log(\sigma_g)}\]</div><p><strong>References</strong></p><p>[1] https://en.wikipedia.org/wiki/Geometric<em>standard</em>deviation</p><p><strong>Examples</strong></p><p>Standardize a lognormal-distributed vector:</p><pre><code class="language-julia-repl">julia&gt; raw = [1,4,5,4,1,2,5,8,6,6,9,8,3]
julia&gt; z = Pingouin.gzscore(raw)
13-element Array{Float64,1}:
 -1.8599725059104346
  0.03137685347921089
  0.3358161014965816
  0.03137685347921089
 -1.8599725059104346
  ⋮
  0.5845610789821727
  0.5845610789821727
  1.1377453044851344
  0.9770515331740336
 -0.3611136007126501</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/distributions.jl#L10-L59">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.homoscedasticity-Tuple{Any}" href="#Pingouin.homoscedasticity-Tuple{Any}"><code>Pingouin.homoscedasticity</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Test equality of variance.</p><p><strong>Arguments</strong></p><ul><li><code>data</code>: Iterable. Can be either an Array iterables or a wide- or long-format dataframe.</li><li><code>dv::Union{Symbol, String, Nothing}</code>: Dependent variable (only when <span>$data$</span> is a long-format dataframe).</li><li><code>group::Union{Symbol, String, Nothing}</code>: Grouping variable (only when <span>$data$</span> is a long-format dataframe).</li><li><code>method::String</code>: Statistical test. <code>&#39;levene&#39;</code> (default) performs the Levene test</li></ul><p>and <code>&#39;bartlett&#39;</code> performs the Bartlett test. The former is more robust to departure from normality.</p><ul><li><code>α::Float64</code>: Significance level.</li></ul><p><strong>Returns</strong></p><ul><li><code>stats::DataFrame</code>:<ul><li><code>W/T</code>: Test statistic (&#39;W&#39; for Levene, &#39;T&#39; for Bartlett), </li><li><code>pval</code>: p-value,</li><li><code>equal_var</code>: true if <code>data</code> has equal variance.</li></ul></li></ul><p><strong>See Also</strong></p><ul><li><a href="#Pingouin.normality-Tuple{Any}"><code>normality</code></a> : Univariate normality test.</li><li><a href="#Pingouin.sphericity-Tuple{DataFrames.DataFrame}"><code>sphericity</code></a> : Mauchly&#39;s test for sphericity.</li></ul><p><strong>Notes</strong></p><p>The <strong>Bartlett</strong> <span>$T$</span> statistic [1] is defined as:</p><div>\[T = \frac{(N-k) \ln{s^{2}_{p}} - \sum_{i=1}^{k}(N_{i} - 1) \ln{s^{2}_{i}}}{1 + (1/(3(k-1)))((\sum_{i=1}^{k}{1/(N_{i} - 1))} - 1/(N-k))}\]</div><p>where <span>$s_i^2$</span> is the variance of the <span>$i^{th}$</span> group, <span>$N$</span> is the total sample size, <span>$N_i$</span> is the sample size of the <span>$i^{th}$</span> group, <span>$k$</span> is the number of groups, and <span>$s_p^2$</span> is the pooled variance.</p><p>The pooled variance is a weighted average of the group variances and is defined as:</p><div>\[s^{2}_{p} = \sum_{i=1}^{k}(N_{i} - 1)s^{2}_{i}/(N-k)\]</div><p>The p-value is then computed using a chi-square distribution:</p><div>\[T \sim \chi^2(k-1)\]</div><p>The <strong>Levene</strong> <span>$W$</span> statistic [2] is defined as:</p><div>\[W = \frac{(N-k)} {(k-1)} \frac{\sum_{i=1}^{k}N_{i}(\overline{Z}_{i.}-\overline{Z})^{2} } {\sum_{i=1}^{k}\sum_{j=1}^{N_i}(Z_{ij}-\overline{Z}_{i.})^{2} }\]</div><p>where <span>$Z_{ij} = |Y_{ij} - \text{median}({Y}_{i.})|$</span>, <span>$\overline{Z}_{i.}$</span> are the group means of <span>$Z_{ij}$</span> and <span>$\overline{Z}$</span> is the grand mean of <span>$Z_{ij}$</span>.</p><p>The p-value is then computed using a F-distribution:</p><div>\[W \sim F(k-1, N-k)\]</div><p><strong>WARNING:</strong> Missing values are not supported for this function. Make sure to remove them before.</p><p><strong>References</strong></p><p>[1] Bartlett, M. S. (1937). Properties of sufficiency and statistical tests. Proc. R. Soc. Lond. A, 160(901), 268-282.</p><p>[2] Brown, M. B., &amp; Forsythe, A. B. (1974). Robust tests for the equality of variances. Journal of the American Statistical Association, 69(346), 364-367.</p><p><strong>Examples</strong></p><ol><li>Levene test on a wide-format dataframe</li></ol><pre><code class="language-julia-repl">julia&gt; data = Pingouin.read_dataset(&quot;mediation&quot;)
julia&gt; Pingouin.homoscedasticity(data[[&quot;X&quot;, &quot;Y&quot;, &quot;M&quot;]])
1×3 DataFrame
│ Row │ W       │ pval     │ equal_var │
│     │ Float64 │ Float64  │ Bool      │
├─────┼─────────┼──────────┼───────────┤
│ 1   │ 1.17352 │ 0.310707 │ 1         │</code></pre><ol><li>Bartlett test using an array of arrays</li></ol><pre><code class="language-julia-repl">julia&gt; data = [[4, 8, 9, 20, 14], [5, 8, 15, 45, 12]]
julia&gt; Pingouin.homoscedasticity(data, method=&quot;bartlett&quot;, α=.05)
1×3 DataFrame
│ Row │ T       │ pval     │ equal_var │
│     │ Float64 │ Float64  │ Bool      │
├─────┼─────────┼──────────┼───────────┤
│ 1   │ 2.87357 │ 0.090045 │ 1         │</code></pre><ol><li>Long-format dataframe</li></ol><pre><code class="language-julia-repl">julia&gt; data = Pingouin.read_dataset(&quot;rm_anova2&quot;)
julia&gt; Pingouin.homoscedasticity(data, dv=&quot;Performance&quot;, group=&quot;Time&quot;)
1×3 DataFrame
│ Row │ W       │ pval      │ equal_var │
│     │ Float64 │ Float64   │ Bool      │
├─────┼─────────┼───────────┼───────────┤
│ 1   │ 3.1922  │ 0.0792169 │ 1         │</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/distributions.jl#L327-L433">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.jarque_bera" href="#Pingouin.jarque_bera"><code>Pingouin.jarque_bera</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Compute the Jarque-Bera statistic to test the null hypothesis that a real-valued vector <span>$y$</span> is normally distributed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/distributions.jl#L314-L316">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.normality-Tuple{Any}" href="#Pingouin.normality-Tuple{Any}"><code>Pingouin.normality</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">normality(data[, dv, group, method, α])</code></pre><p>Univariate normality test.</p><p><strong>Arguments</strong></p><ul><li><code>data</code>: Iterable. Can be either a single list, 1D array, or a wide- or long-format dataframe.</li><li><code>dv::Union{Symbol, String, Nothing}</code>: Dependent variable (only when <span>$data$</span> is a long-format dataframe).</li><li><code>group::Union{Symbol, String, Nothing}</code>: Grouping variable (only when <span>$data$</span> is a long-format dataframe).</li><li><code>method::String</code>: Normality test. <code>&#39;shapiro&#39;</code> (default) performs the Shapiro-Wilk test</li></ul><p>using the AS R94 algorithm. If the kurtosis is higher than 3, it  performs a Shapiro-Francia test for leptokurtic distributions. Supported values: [&quot;shapiro&quot;, &quot;jarque_bera&quot;].</p><ul><li><code>α::Float64</code>: Significance level.</li></ul><p><strong>Returns</strong></p><ul><li><code>stats::DataFrame</code>:<ul><li><code>W</code>: Test statistic,</li><li><code>pval</code>: p-value,</li><li><code>normal</code>: true if <code>data</code> is normally distributed.</li></ul></li></ul><p><strong>See Also</strong></p><ul><li><a href="#Pingouin.homoscedasticity-Tuple{Any}"><code>homoscedasticity</code></a>: Test equality of variance.</li><li><a href="#Pingouin.sphericity-Tuple{DataFrames.DataFrame}"><code>sphericity</code></a>: Mauchly&#39;s test for sphericity.</li></ul><p><strong>Notes</strong></p><p>The Shapiro-Wilk test calculates a :math:<code>W</code> statistic that tests whether a random sample <span>$x_1, x_2, ..., x_n$</span> comes from a normal distribution.</p><p>The <span>$W$</span> is normalized (<span>$W = (W - μ) / σ$</span>)</p><p>The null-hypothesis of this test is that the population is normally distributed. Thus, if the p-value is less than the chosen alpha level (typically set at 0.05), then the null hypothesis is rejected and there is evidence that the data tested are not normally distributed.</p><p>The result of the Shapiro-Wilk test should be interpreted with caution in the case of large sample sizes (&gt;5000). Indeed, quoting from <a href="https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test">Wikipedia</a>:</p><p><em>&quot;Like most statistical significance tests, if the sample size is sufficiently large this test may detect even trivial departures from the null hypothesis (i.e., although there may be some statistically significant effect, it may be too small to be of any practical significance); thus, additional investigation of the effect size is typically advisable, e.g., a Q–Q plot in this case.&quot;</em></p><p>The Jarque-Bera statistic is to test the null hypothesis that a real-valued vector <span>$y$</span> is normally distributed. Note that the approximation by the Chi-squared distribution does not work well and the speed of convergence is slow. In small samples, the test tends to be over-sized for nominal levels up to about 3% and under-sized for larger nominal levels (Mantalos, 2010).</p><p>Note that missing values are automatically removed (casewise deletion).</p><p><strong>References</strong></p><ul><li>Shapiro, S. S., &amp; Wilk, M. B. (1965). An analysis of variance test</li></ul><p>for normality (complete samples). Biometrika, 52(3/4), 591-611.</p><ul><li>Panagiotis Mantalos, 2011, &quot;The three different measures of the sample skewness and</li></ul><p>kurtosis and the effects to the Jarque-Bera test for normality&quot;, International Journal of Computational Economics and Econometrics, Vol. 2, No. 1, <a href="http://dx.doi.org/10.1504/IJCEE.2011.040576">link</a>.</p><ul><li><p>https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm</p></li><li><p><a href="https://en.wikipedia.org/wiki/Jarque–Bera_test">Jarque-Bera test on Wikipedia</a></p></li></ul><p><strong>Examples</strong></p><ol><li>Shapiro-Wilk test on a 1D array</li></ol><pre><code class="language-julia-repl">julia&gt; dataset = Pingouin.read_dataset(&quot;anova&quot;)
julia&gt; Pingouin.normality(dataset[&quot;Pain threshold&quot;])
1×3 DataFrame
│ Row │ W         │ pval     │ normal │
│     │ Float64   │ Float64  │ Bool   │
├─────┼───────────┼──────────┼────────┤
│ 1   │ -0.842541 │ 0.800257 │ 1      │</code></pre><ol><li>Wide-format dataframe using Jarque-Bera test</li></ol><pre><code class="language-julia-repl">julia&gt; dataset = Pingouin.read_dataset(&quot;mediation&quot;)
julia&gt; Pingouin.normality(dataset, method=&quot;jarque_bera&quot;)
│ Row │ dv     │ W        │ pval        │ normal │
│     │ Symbol │ Float64  │ Float64     │ Bool   │
├─────┼────────┼──────────┼─────────────┼────────┤
│ 1   │ X      │ 1.42418  │ 0.490618    │ 1      │
│ 2   │ M      │ 0.645823 │ 0.724038    │ 1      │
│ 3   │ Y      │ 0.261805 │ 0.877303    │ 1      │
│ 4   │ Mbin   │ 16.6735  │ 0.000239553 │ 0      │
│ 5   │ Ybin   │ 16.6675  │ 0.000240265 │ 0      │
│ 6   │ W1     │ 5.40923  │ 0.0668961   │ 1      │
│ 7   │ W2     │ 80.6857  │ 3.01529e-18 │ 0      │</code></pre><ol><li>Long-format dataframe</li></ol><pre><code class="language-julia-repl">julia&gt; dataset = Pingouin.read_dataset(&quot;rm_anova2&quot;)
julia&gt; Pingouin.normality(dataset, dv=:Performance, group=:Time)
│ Row │ Time   │ W         │ pval      │ normal │
│     │ String │ Float64   │ Float64   │ Bool   │
├─────┼────────┼───────────┼───────────┼────────┤
│ 1   │ Pre    │ 0.0532374 │ 0.478771  │ 1      │
│ 2   │ Post   │ 1.30965   │ 0.0951576 │ 1      │</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/distributions.jl#L128-L244">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.shapiro" href="#Pingouin.shapiro"><code>Pingouin.shapiro</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Compute the Shapiro-Wilk statistic to test the null hypothesis that a real-valued vector <span>$y$</span> is normally distributed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/distributions.jl#L289-L291">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.sphericity-Tuple{DataFrames.DataFrame}" href="#Pingouin.sphericity-Tuple{DataFrames.DataFrame}"><code>Pingouin.sphericity</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">sphericity(data[, dv, within, subject, method, α])</code></pre><p>Mauchly and JNS test for sphericity.</p><p><strong>Parameters</strong></p><ul><li><code>data::DataFrame</code>: DataFrame containing the repeated measurements. Only long-format dataframe are supported for this function.</li><li><code>dv::Union{Nothing, String, Symbol}</code>: Name of column containing the dependent variable.</li><li><code>within::Union{Array{String}, Array{Symbol}, Nothing, String, Symbol}</code>: Name of column containing the within factor. If <code>within</code> is a list with two strings, this function computes the epsilon factor for the interaction between the two within-subject factor.</li><li><code>subject::Union{Nothing, String, Symbol}</code>: Name of column containing the subject identifier (only required if <code>data</code> is in long format).</li><li><code>method::String</code>: Method to compute sphericity:<ul><li><code>&quot;jns&quot;</code>: John, Nagao and Sugiura test.</li><li><code>&quot;mauchly&quot;</code>: Mauchly test (default).</li></ul></li><li><code>α::Float64</code>: Significance level</li></ul><p><strong>Returns</strong></p><ul><li><code>spher::Bool</code>: True if data have the sphericity property.</li><li><code>W::Float64:</code> Test statistic.</li><li><code>chi2::Float64</code>: Chi-square statistic.</li><li><code>dof::Int64</code>:  Degrees of freedom.</li><li><code>pval::Flot64</code>: P-value.</li></ul><p><strong>Throwing</strong></p><p><code>DomainError</code> When testing for an interaction, if both within-subject factors have more than 2 levels (not yet supported in Pingouin).</p><p><strong>See Also</strong></p><ul><li><a href="#Pingouin.epsilon-Tuple{Union{DataFrames.DataFrame, Array{var&quot;#s30&quot;,N} where N where var&quot;#s30&quot;&lt;:Number}}"><code>epsilon</code></a>: Epsilon adjustement factor for repeated measures.</li><li><a href="#Pingouin.homoscedasticity-Tuple{Any}"><code>homoscedasticity</code></a>: Test equality of variance.</li><li><a href="#Pingouin.normality-Tuple{Any}"><code>normality</code></a>: Univariate normality test.</li></ul><p><strong>Notes</strong></p><p>The <strong>Mauchly</strong> <span>$W$</span> statistic [1] is defined by:</p><div>\[W = \frac{\prod \lambda_j}{(\frac{1}{k-1} \sum \lambda_j)^{k-1}}\]</div><p>where <span>$\lambda_j$</span> are the eigenvalues of the population covariance matrix (= double-centered sample covariance matrix) and <span>$k$</span> is the number of conditions.</p><p>From then, the <span>$W$</span> statistic is transformed into a chi-square score using the number of observations per condition <span>$n$</span></p><div>\[f = \frac{2(k-1)^2+k+1}{6(k-1)(n-1)}\]</div><div>\[\chi_w^2 = (f-1)(n-1) \text{log}(W)\]</div><p>The p-value is then approximated using a chi-square distribution:</p><div>\[\chi_w^2 \sim \chi^2(\frac{k(k-1)}{2}-1)\]</div><p>The <strong>JNS</strong> <span>$V$</span> statistic ([2], [3], [4]) is defined by:</p><div>\[V = \frac{(\sum_j^{k-1} \lambda_j)^2}{\sum_j^{k-1} \lambda_j^2}\]</div><div>\[\chi_v^2 = \frac{n}{2}  (k-1)^2 (V - \frac{1}{k-1})\]</div><p>and the p-value approximated using a chi-square distribution</p><div>\[\chi_v^2 \sim \chi^2(\frac{k(k-1)}{2}-1)\]</div><p>Missing values are automatically removed from <code>data</code> (listwise deletion).</p><p><strong>References</strong></p><p>[1] Mauchly, J. W. (1940). Significance test for sphericity of a normal n-variate distribution. The Annals of Mathematical Statistics, 11(2), 204-209.</p><p>[2] Nagao, H. (1973). On some test criteria for covariance matrix. The Annals of Statistics, 700-709.</p><p>[3] Sugiura, N. (1972). Locally best invariant test for sphericity and the limiting distributions. The Annals of Mathematical Statistics, 1312-1316.</p><p>[4] John, S. (1972). The distribution of a statistic used for testing sphericity of normal distributions. Biometrika, 59(1), 169-173.</p><p>See also http://www.real-statistics.com/anova-repeated-measures/sphericity/</p><p><strong>Examples</strong></p><p>Mauchly test for sphericity using a wide-format dataframe</p><pre><code class="language-julia-repl">julia&gt; data = DataFrame(A = [2.2, 3.1, 4.3, 4.1, 7.2],
                     B = [1.1, 2.5, 4.1, 5.2, 6.4],
                     C = [8.2, 4.5, 3.4, 6.2, 7.2])
julia&gt; Pingouin.sphericity(data)
│ Row │ spher │ W        │ chi2    │ dof     │ pval      │
│     │ Bool  │ Float64  │ Float64 │ Float64 │ Float64   │
├─────┼───────┼──────────┼─────────┼─────────┼───────────┤
│ 1   │ 1     │ 0.210372 │ 4.67663 │ 2.0     │ 0.0964902 │</code></pre><p>John, Nagao and Sugiura (JNS) test</p><pre><code class="language-julia-repl">julia&gt; Pingouin.sphericity(data, method=&quot;jns&quot;)[:pval]  # P-value only
0.045604240307520305</code></pre><p>Now using a long-format dataframe</p><pre><code class="language-julia-repl">julia&gt; data = Pingouin.read_dataset(&quot;rm_anova2&quot;)
julia&gt; head(data)
6x4 DataFrame
│ Row │ Subject │ Time   │ Metric  │ Performance │
│     │ Int64   │ String │ String  │ Int64       │
├─────┼─────────┼────────┼─────────┼─────────────┤
│ 1   │ 1       │ Pre    │ Product │ 13          │
│ 2   │ 2       │ Pre    │ Product │ 12          │
│ 3   │ 3       │ Pre    │ Product │ 17          │
│ 4   │ 4       │ Pre    │ Product │ 12          │
│ 5   │ 5       │ Pre    │ Product │ 19          │
│ 6   │ 6       │ Pre    │ Product │ 6           │</code></pre><p>Let&#39;s first test sphericity for the <em>Time</em> within-subject factor</p><pre><code class="language-julia-repl">julia&gt; Pingouin.sphericity(data, dv=:Performance, subject=:Subject,
                        within=:Time)
│ Row │ spher │ W       │ chi2    │ dof   │ pval    │
│     │ Bool  │ Float64 │ Float64 │ Int64 │ Float64 │
├─────┼───────┼─────────┼─────────┼───────┼─────────┤
│ 1   │ 1     │ NaN     │ NaN     │ 1     │ 1.0     │</code></pre><p>Since <em>Time</em> has only two levels (Pre and Post), the sphericity assumption is necessarily met.</p><p>The <em>Metric</em> factor, however, has three levels:</p><pre><code class="language-julia-repl">julia&gt; Pingouin.sphericity(data, dv=&quot;Performance&quot;, subject=&quot;Subject&quot;,
                        within=[&quot;Metric&quot;])[:pval]
0.8784417991645139</code></pre><p>The p-value value is very large, and the test therefore indicates that there is no violation of sphericity.</p><p>Now, let&#39;s calculate the epsilon for the interaction between the two repeated measures factor. The current implementation in Pingouin only works if at least one of the two within-subject factors has no more than two levels.</p><pre><code class="language-julia-repl">julia&gt; Pingouin.sphericity(data, dv=&quot;Performance&quot;,
                        subject=&quot;Subject&quot;,
                        within=[&quot;Time&quot;, &quot;Metric&quot;])
│ Row │ spher │ W        │ chi2    │ dof     │ pval     │
│     │ Bool  │ Float64  │ Float64 │ Float64 │ Float64  │
├─────┼───────┼──────────┼─────────┼─────────┼──────────┤
│ 1   │ 1     │ 0.624799 │ 3.7626  │ 2.0     │ 0.152392 │</code></pre><p>Here again, there is no violation of sphericity acccording to Mauchly&#39;s test.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/distributions.jl#L496-L661">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.madmedianrule-Tuple{Array{var&quot;#s123&quot;,N} where N where var&quot;#s123&quot;&lt;:Number}" href="#Pingouin.madmedianrule-Tuple{Array{var&quot;#s123&quot;,N} where N where var&quot;#s123&quot;&lt;:Number}"><code>Pingouin.madmedianrule</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">madmedianrule(a)</code></pre><p>Robust outlier detection based on the MAD-median rule.</p><p><strong>Parameters</strong></p><ul><li><code>a::Array{&lt;:Number}</code>: Input array. Must be one-dimensional.</li></ul><p><strong>Returns</strong></p><ul><li><code>outliers::Array{Bool}</code>: Boolean array indicating whether each sample is an outlier (true) or not (false).</li></ul><p><strong>See also</strong></p><p><code>Statistics.mad</code></p><p><strong>Notes</strong></p><p>The MAD-median-rule ([1], [2]) will refer to declaring <span>$X_i$</span> an outlier if</p><div>\[\frac{\left | X_i - M \right |}{\text{MAD}_{\text{norm}}} &gt; K\]</div><p>,</p><p>where <span>$M$</span> is the median of <span>$X$</span>, <span>$\text{MAD}_{\text{norm}}$</span> the normalized median absolute deviation of <span>$X$</span>, and <span>$K$</span> is the square root of the .975 quantile of a <span>$X^2$</span> distribution with one degree of freedom, which is roughly equal to 2.24.</p><p><strong>References</strong></p><p>[1] Hall, P., Welsh, A.H., 1985. Limit theorems for the median deviation. Ann. Inst. Stat. Math. 37, 27–36. https://doi.org/10.1007/BF02481078</p><p>[2] Wilcox, R. R. Introduction to Robust Estimation and Hypothesis Testing. (Academic Press, 2011).</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; a = [-1.09, 1., 0.28, -1.51, -0.58, 6.61, -2.43, -0.43]
julia&gt; Pingouin.madmedianrule(a)
8-element Array{Bool,1}:
 0
 0
 0
 0
 0
 1
 0
 0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/nonparametric.jl#L8-L62">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.mwu-Tuple{Array{var&quot;#s122&quot;,N} where N where var&quot;#s122&quot;&lt;:Number,Array{var&quot;#s121&quot;,N} where N where var&quot;#s121&quot;&lt;:Number}" href="#Pingouin.mwu-Tuple{Array{var&quot;#s122&quot;,N} where N where var&quot;#s122&quot;&lt;:Number,Array{var&quot;#s121&quot;,N} where N where var&quot;#s121&quot;&lt;:Number}"><code>Pingouin.mwu</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mwu(x, y)</code></pre><p>Mann-Whitney U Test (= Wilcoxon rank-sum test). It is the non-parametric version of the independent T-test.</p><p><strong>Parameters</strong></p><ul><li><code>x, y::Array{&lt;:Number}</code>: First and second set of observations. <code>x</code> and <code>y</code> must be independent.</li></ul><p><strong>Returns</strong></p><ul><li><code>stats::DataFrame</code><ul><li><code>&#39;U-val&#39;</code>: U-value</li><li><code>&#39;p-val&#39;</code>: p-value</li><li><code>&#39;RBC&#39;</code>: rank-biserial correlation</li><li><code>&#39;CLES&#39;</code>: common language effect size</li></ul></li></ul><p><strong>See also</strong></p><ul><li><code>HypothesisTests.MannWhitneyUTest</code>,</li><li><a href="#Pingouin.wilcoxon-Tuple{Array{var&quot;#s122&quot;,N} where N where var&quot;#s122&quot;&lt;:Number,Array{var&quot;#s121&quot;,N} where N where var&quot;#s121&quot;&lt;:Number}"><code>wilcoxon</code></a>,</li><li><a href="@ref"><code>ttest</code></a>.</li></ul><p><strong>Notes</strong></p><p>The Mann–Whitney U test [1], (also called Wilcoxon rank-sum test) is a non-parametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. The test assumes that the two samples are independent. This test corrects for ties and by default uses a continuity correction (see <code>HypothesisTests.MannWhitneyUTest</code> for details).</p><p>The rank biserial correlation [2] is the difference between the proportion of favorable evidence minus the proportion of unfavorable evidence.</p><p>The common language effect size is the proportion of pairs where <span>$x$</span> is higher than <span>$y$</span>. It was first introduced by McGraw and Wong (1992) [3]. Pingouin uses a brute-force version of the formula given by Vargha and Delaney 2000 [4]:</p><div>\[\text{CL} = P(X &gt; Y) + .5 \times P(X = Y)\]</div><p>The advantage is of this method are twofold. First, the brute-force approach pairs each observation of <span>$x$</span> to its <span>$y$</span> counterpart, and therefore does not require normally distributed data. Second, the formula takes ties into account and therefore works with ordinal data.</p><p><strong>References</strong></p><p>[1] Mann, H. B., &amp; Whitney, D. R. (1947). On a test of whether one of two random variables is stochastically larger than the other. The annals of mathematical statistics, 50-60.</p><p>[2] Kerby, D. S. (2014). The simple difference formula: An approach to teaching nonparametric correlation. Comprehensive Psychology, 3, 11-IT.</p><p>[3] McGraw, K. O., &amp; Wong, S. P. (1992). A common language effect size statistic. Psychological bulletin, 111(2), 361.</p><p>[4] Vargha, A., &amp; Delaney, H. D. (2000). A Critique and Improvement of the “CL” Common Language Effect Size Statistics of McGraw and Wong. Journal of Educational and Behavioral Statistics: A Quarterly Publication Sponsored by the American Educational Research Association and the American Statistical Association, 25(2), 101–132. https://doi.org/10.2307/1165329</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; x = [1,4,2,5,3,6,9,8,7]
julia&gt; y = [2,4,1,5,10,1,4,9,8,5]
julia&gt; Pingouin.mwu(x, y)
1×4 DataFrame
│ Row │ U_val   │ p_val    │ RBC        │ CLES     │
│     │ Float64 │ Float64  │ Float64    │ Float64  │
├─────┼─────────┼──────────┼────────────┼──────────┤
│ 1   │ 46.5    │ 0.934494 │ -0.0333333 │ 0.516667 │</code></pre><p>Compare with HypothesisTests</p><pre><code class="language-julia-repl">julia&gt; using HypothesisTests
julia&gt; MannWhitneyUTest(x, y)
Approximate Mann-Whitney U test
-------------------------------
Population details:
    parameter of interest:   Location parameter (pseudomedian)
    value under h_0:         0
    point estimate:          0.5

Test summary:
    outcome with 95% confidence: fail to reject h_0
    two-sided p-value:           0.9345

Details:
    number of observations in each group: [9, 10]
    Mann-Whitney-U statistic:             46.5
    rank sums:                            [91.5, 98.5]
    adjustment for ties:                  90.0
    normal approximation (μ, σ):          (1.5, 12.1666)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/nonparametric.jl#L70-L176">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.wilcoxon-Tuple{Array{var&quot;#s122&quot;,N} where N where var&quot;#s122&quot;&lt;:Number,Array{var&quot;#s121&quot;,N} where N where var&quot;#s121&quot;&lt;:Number}" href="#Pingouin.wilcoxon-Tuple{Array{var&quot;#s122&quot;,N} where N where var&quot;#s122&quot;&lt;:Number,Array{var&quot;#s121&quot;,N} where N where var&quot;#s121&quot;&lt;:Number}"><code>Pingouin.wilcoxon</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">wilcoxon(x, y)</code></pre><p>Wilcoxon signed-rank test. It is the non-parametric version of the paired T-test.</p><p><strong>Parameters</strong></p><ul><li><code>x, y::Array{&lt;:Number}</code>: First and second set of observations. <span>$x$</span> and <span>$y$</span> must be related (e.g repeated measures) and, therefore, have the same number of samples. Note that a listwise deletion of missing values is automatically applied.</li></ul><p><strong>Returns</strong></p><ul><li><code>stats::DataFrame</code><ul><li><code>&#39;W-val&#39;</code>: W-value</li><li><code>&#39;p-val&#39;</code>: p-value</li><li><code>&#39;RBC&#39;</code>: matched pairs rank-biserial correlation (effect size)</li><li><code>&#39;CLES&#39;</code>: common language effect size</li></ul></li></ul><p><strong>See also</strong></p><ul><li><code>HypothesisTests.SignedRankTest</code>,</li><li><a href="#Pingouin.mwu-Tuple{Array{var&quot;#s122&quot;,N} where N where var&quot;#s122&quot;&lt;:Number,Array{var&quot;#s121&quot;,N} where N where var&quot;#s121&quot;&lt;:Number}"><code>mwu</code></a>.</li></ul><p><strong>Notes</strong></p><p>The Wilcoxon signed-rank test [1] tests the null hypothesis that two related paired samples come from the same distribution. In particular, it tests whether the distribution of the differences <span>$x - y$</span> is symmetric about zero. A continuity correction is applied by default (see <code>HypothesisTests.SignedRankTest</code> for details).</p><p>The matched pairs rank biserial correlation [2] is the simple difference between the proportion of favorable and unfavorable evidence; in the case of the Wilcoxon signed-rank test, the evidence consists of rank sums (Kerby 2014):</p><div>\[r = f - u\]</div><p>The common language effect size is the proportion of pairs where <span>$x$</span> is higher than <span>$y$</span>. It was first introduced by McGraw and Wong (1992) [3]. Pingouin uses a brute-force version of the formula given by Vargha and Delaney 2000 [4]:</p><div>\[\text{CL} = P(X &gt; Y) + .5 \times P(X = Y)\]</div><p>The advantage is of this method are twofold. First, the brute-force approach pairs each observation of <span>$x$</span> to its <span>$y$</span> counterpart, and therefore does not require normally distributed data. Second, the formula takes ties into account and therefore works with ordinal data.</p><p><strong>References</strong></p><p>[1] Wilcoxon, F. (1945). Individual comparisons by ranking methods. Biometrics bulletin, 1(6), 80-83.</p><p>[2] Kerby, D. S. (2014). The simple difference formula: An approach to teaching nonparametric correlation. Comprehensive Psychology, 3, 11-IT.</p><p>[3] McGraw, K. O., &amp; Wong, S. P. (1992). A common language effect size statistic. Psychological bulletin, 111(2), 361.</p><p>[4] Vargha, A., &amp; Delaney, H. D. (2000). A Critique and Improvement of the “CL” Common Language Effect Size Statistics of McGraw and Wong. Journal of Educational and Behavioral Statistics: A Quarterly Publication Sponsored by the American Educational Research Association and the American Statistical Association, 25(2), 101–132. https://doi.org/10.2307/1165329</p><p><strong>Examples</strong></p><p>Wilcoxon test on two related samples.</p><pre><code class="language-julia-repl">julia&gt; x = [20, 22, 19, 20, 22, 18, 24, 20, 19, 24, 26, 13]
julia&gt; y = [38, 37, 33, 29, 14, 12, 20, 22, 17, 25, 26, 16]
julia&gt; Pingouin.wilcoxon(x, y)
1×4 DataFrame
│ Row │ W_val   │ p_val    │ RBC       │ CLES     │
│     │ Float64 │ Float64  │ Float64   │ Float64  │
├─────┼─────────┼──────────┼───────────┼──────────┤
│ 1   │ 20.5    │ 0.288086 │ -0.378788 │ 0.395833 │</code></pre><p>Compare with HypothesisTests</p><pre><code class="language-julia-repl">julia&gt; using HypothesisTests
julia&gt; SignedRankTest(x, y)
Exact Wilcoxon signed rank test
-------------------------------
Population details:
    parameter of interest:   Location parameter (pseudomedian)
    value under h_0:         0
    point estimate:          -1.5
    95% confidence interval: (-9.0, 2.5)

Test summary:
    outcome with 95% confidence: fail to reject h_0
    two-sided p-value:           0.2881

Details:
    number of observations:      12
    Wilcoxon rank-sum statistic: 20.5
    rank sums:                   [20.5, 45.5]
    adjustment for ties:         6.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/nonparametric.jl#L200-L307">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.compute_bootci-Tuple{Array{var&quot;#s12&quot;,N} where N where var&quot;#s12&quot;&lt;:Number}" href="#Pingouin.compute_bootci-Tuple{Array{var&quot;#s12&quot;,N} where N where var&quot;#s12&quot;&lt;:Number}"><code>Pingouin.compute_bootci</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Bootstrapped confidence intervals of univariate and bivariate functions.</p><p><strong>Parameters</strong></p><p>x : 1D-array     First sample. Required for both bivariate and univariate functions. y : 1D-array, nothing     Second sample. Required only for bivariate functions. func : str or custom function     Function to compute the bootstrapped statistic.     Accepted string values are:</p><pre><code class="language-none">* ``&#39;pearson&#39;``: Pearson correlation (bivariate, requires x and y)
* ``&#39;spearman&#39;``: Spearman correlation (bivariate)
* ``&#39;cohen&#39;``: Cohen d effect size (bivariate)
* ``&#39;hedges&#39;``: Hedges g effect size (bivariate)
* ``&#39;mean&#39;``: Mean (univariate, requires only x)
* ``&#39;std&#39;``: Standard deviation (univariate)
* ``&#39;var&#39;``: Variance (univariate)</code></pre><p>method : str     Method to compute the confidence intervals:</p><pre><code class="language-none">* ``&#39;norm&#39;``: Normal approximation with bootstrapped bias and
    standard error
* ``&#39;per&#39;``: Basic percentile method
* ``&#39;cper&#39;``: Bias corrected percentile method (default)</code></pre><p>paired : boolean     Indicates whether x and y are paired or not. Only useful when computing     bivariate Cohen d or Hedges g bootstrapped confidence intervals. confidence : float     Confidence level (0.95 = 95%) n<em>boot : int     Number of bootstrap iterations. The higher, the better, the slower. decimals : int     Number of rounded decimals. seed : int or None     Random seed for generating bootstrap samples. return</em>dist : boolean     If True, return the confidence intervals and the bootstrapped     distribution  (e.g. for plotting purposes).</p><p><strong>Returns</strong></p><p>ci : array     Desired converted effect size</p><p><strong>Notes</strong></p><p>Results have been tested against the <code>bootci &lt;https://www.mathworks.com/help/stats/bootci.html&gt;</code>_ Matlab function.</p><p><strong>References</strong></p><ul><li><p>DiCiccio, T. J., &amp; Efron, B. (1996). Bootstrap confidence intervals.   Statistical science, 189-212.</p></li><li><p>Davison, A. C., &amp; Hinkley, D. V. (1997). Bootstrap methods and their   application (Vol. 1). Cambridge university press.</p></li></ul><p><strong>Examples</strong></p><ol><li>Bootstrapped 95% confidence interval of a Pearson correlation</li></ol><blockquote><blockquote><blockquote><p>x = [3, 4, 6, 7, 5, 6, 7, 3, 5, 4, 2] y = [4, 6, 6, 7, 6, 5, 5, 2, 3, 4, 1] stat = cor(x, y)</p></blockquote></blockquote></blockquote><p>0.7468280049029223</p><blockquote><blockquote><blockquote><p>ci = Pingouin.compute_bootci(x=x, y=y, func=&quot;pearson&quot;, seed=42)</p></blockquote></blockquote></blockquote><p>2-element Array{Float64,1}:  0.22  0.93</p><ol><li>Bootstrapped 95% confidence interval of a Cohen d</li></ol><blockquote><blockquote><blockquote><p>stat = Pingouin.compute_effsize(x, y, eftype=&quot;cohen&quot;)</p></blockquote></blockquote></blockquote><p>0.1537753990658328</p><blockquote><blockquote><blockquote><p>ci = Pingouin.compute_bootci(x, y=y, func=&quot;cohen&quot;, seed=42, decimals=3)</p></blockquote></blockquote></blockquote><p>2-element Array{Float64,1}:  -0.329   0.589</p><ol><li>Bootstrapped confidence interval of a standard deviation (univariate)</li></ol><blockquote><blockquote><blockquote><p>stat = std(x)</p></blockquote></blockquote></blockquote><p>1.6787441193290351</p><blockquote><blockquote><blockquote><p>ci = Pingouin.compute_bootci(x, func=&quot;std&quot;, seed=123)</p></blockquote></blockquote></blockquote><p>2-element Array{Float64,1}:  1.25  2.2</p><ol><li>Bootstrapped confidence interval using a custom univariate function</li></ol><blockquote><blockquote><blockquote><p>skewness(x), Pingouin.compute<em>bootci(x, func=skewness, n</em>boot=10000, seed=123)</p></blockquote></blockquote></blockquote><p>(-0.08244607271328411, [-1.01, 0.77])</p><ol><li>Bootstrapped confidence interval using a custom bivariate function</li></ol><blockquote><blockquote><blockquote><p>stat = sum(exp.(x) ./ exp.(y))</p></blockquote></blockquote></blockquote><p>26.80405184881793</p><blockquote><blockquote><blockquote><p>ci = Pingouin.compute<em>bootci(x, y=y, func=f(x, y) = sum(exp.(x) ./ exp.(y)), n</em>boot=10000, seed=123) print(stat, ci)</p></blockquote></blockquote></blockquote><p>2-element Array{Float64,1}:  12.76  45.52</p><ol><li>Get the bootstrapped distribution around a Pearson correlation</li></ol><blockquote><blockquote><blockquote><p>ci, bstat = Pingouin.compute<em>bootci(x, y=y, return</em>dist=true)</p></blockquote></blockquote></blockquote><p>([0.27, 0.92], [0.6661370089058535, ...])</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/effsize.jl#L589-L700">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.compute_bootci-Tuple{Array{var&quot;#s33&quot;,N} where N where var&quot;#s33&quot;&lt;:Number}" href="#Pingouin.compute_bootci-Tuple{Array{var&quot;#s33&quot;,N} where N where var&quot;#s33&quot;&lt;:Number}"><code>Pingouin.compute_bootci</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Bootstrapped confidence intervals of univariate and bivariate functions.</p><p><strong>Parameters</strong></p><p>x : 1D-array     First sample. Required for both bivariate and univariate functions. y : 1D-array, nothing     Second sample. Required only for bivariate functions. func : str or custom function     Function to compute the bootstrapped statistic.     Accepted string values are:</p><pre><code class="language-none">* ``&#39;pearson&#39;``: Pearson correlation (bivariate, requires x and y)
* ``&#39;spearman&#39;``: Spearman correlation (bivariate)
* ``&#39;cohen&#39;``: Cohen d effect size (bivariate)
* ``&#39;hedges&#39;``: Hedges g effect size (bivariate)
* ``&#39;mean&#39;``: Mean (univariate, requires only x)
* ``&#39;std&#39;``: Standard deviation (univariate)
* ``&#39;var&#39;``: Variance (univariate)</code></pre><p>method : str     Method to compute the confidence intervals:</p><pre><code class="language-none">* ``&#39;norm&#39;``: Normal approximation with bootstrapped bias and
    standard error
* ``&#39;per&#39;``: Basic percentile method
* ``&#39;cper&#39;``: Bias corrected percentile method (default)</code></pre><p>paired : boolean     Indicates whether x and y are paired or not. Only useful when computing     bivariate Cohen d or Hedges g bootstrapped confidence intervals. confidence : float     Confidence level (0.95 = 95%) n<em>boot : int     Number of bootstrap iterations. The higher, the better, the slower. decimals : int     Number of rounded decimals. seed : int or None     Random seed for generating bootstrap samples. return</em>dist : boolean     If True, return the confidence intervals and the bootstrapped     distribution  (e.g. for plotting purposes).</p><p><strong>Returns</strong></p><p>ci : array     Desired converted effect size</p><p><strong>Notes</strong></p><p>Results have been tested against the <code>bootci &lt;https://www.mathworks.com/help/stats/bootci.html&gt;</code>_ Matlab function.</p><p><strong>References</strong></p><ul><li><p>DiCiccio, T. J., &amp; Efron, B. (1996). Bootstrap confidence intervals.   Statistical science, 189-212.</p></li><li><p>Davison, A. C., &amp; Hinkley, D. V. (1997). Bootstrap methods and their   application (Vol. 1). Cambridge university press.</p></li></ul><p><strong>Examples</strong></p><ol><li>Bootstrapped 95% confidence interval of a Pearson correlation</li></ol><blockquote><blockquote><blockquote><p>x = [3, 4, 6, 7, 5, 6, 7, 3, 5, 4, 2] y = [4, 6, 6, 7, 6, 5, 5, 2, 3, 4, 1] stat = cor(x, y)</p></blockquote></blockquote></blockquote><p>0.7468280049029223</p><blockquote><blockquote><blockquote><p>ci = Pingouin.compute_bootci(x=x, y=y, func=&quot;pearson&quot;, seed=42)</p></blockquote></blockquote></blockquote><p>2-element Array{Float64,1}:  0.22  0.93</p><ol><li>Bootstrapped 95% confidence interval of a Cohen d</li></ol><blockquote><blockquote><blockquote><p>stat = Pingouin.compute_effsize(x, y, eftype=&quot;cohen&quot;)</p></blockquote></blockquote></blockquote><p>0.1537753990658328</p><blockquote><blockquote><blockquote><p>ci = Pingouin.compute_bootci(x, y=y, func=&quot;cohen&quot;, seed=42, decimals=3)</p></blockquote></blockquote></blockquote><p>2-element Array{Float64,1}:  -0.329   0.589</p><ol><li>Bootstrapped confidence interval of a standard deviation (univariate)</li></ol><blockquote><blockquote><blockquote><p>stat = std(x)</p></blockquote></blockquote></blockquote><p>1.6787441193290351</p><blockquote><blockquote><blockquote><p>ci = Pingouin.compute_bootci(x, func=&quot;std&quot;, seed=123)</p></blockquote></blockquote></blockquote><p>2-element Array{Float64,1}:  1.25  2.2</p><ol><li>Bootstrapped confidence interval using a custom univariate function</li></ol><blockquote><blockquote><blockquote><p>skewness(x), Pingouin.compute<em>bootci(x, func=skewness, n</em>boot=10000, seed=123)</p></blockquote></blockquote></blockquote><p>(-0.08244607271328411, [-1.01, 0.77])</p><ol><li>Bootstrapped confidence interval using a custom bivariate function</li></ol><blockquote><blockquote><blockquote><p>stat = sum(exp.(x) ./ exp.(y))</p></blockquote></blockquote></blockquote><p>26.80405184881793</p><blockquote><blockquote><blockquote><p>ci = Pingouin.compute<em>bootci(x, y=y, func=f(x, y) = sum(exp.(x) ./ exp.(y)), n</em>boot=10000, seed=123) print(stat, ci)</p></blockquote></blockquote></blockquote><p>2-element Array{Float64,1}:  12.76  45.52</p><ol><li>Get the bootstrapped distribution around a Pearson correlation</li></ol><blockquote><blockquote><blockquote><p>ci, bstat = Pingouin.compute<em>bootci(x, y=y, return</em>dist=true)</p></blockquote></blockquote></blockquote><p>([0.27, 0.92], [0.6661370089058535, ...])</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/effsize.jl#L589-L700">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.compute_effsize-Tuple{Array{var&quot;#s117&quot;,N} where N where var&quot;#s117&quot;&lt;:Number,Array{var&quot;#s116&quot;,N} where N where var&quot;#s116&quot;&lt;:Number}" href="#Pingouin.compute_effsize-Tuple{Array{var&quot;#s117&quot;,N} where N where var&quot;#s117&quot;&lt;:Number,Array{var&quot;#s116&quot;,N} where N where var&quot;#s116&quot;&lt;:Number}"><code>Pingouin.compute_effsize</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Calculate effect size between two set of observations.</p><p><strong>Parameters</strong></p><p>x : array     First set of observations. y : array     Second set of observations. paired : boolean     If True, uses Cohen d-avg formula to correct for repeated measurements     (see Notes). eftype : string     Desired output effect size.     Available methods are:</p><pre><code class="language-none">* ``&#39;none&#39;``: no effect size
* ``&#39;cohen&#39;``: Unbiased Cohen d
* ``&#39;hedges&#39;``: Hedges g
* ``&#39;glass&#39;``: Glass delta
* ``&#39;r&#39;``: correlation coefficient
* ``&#39;eta-square&#39;``: Eta-square
* ``&#39;odds-ratio&#39;``: Odds ratio
* ``&#39;auc&#39;``: Area Under the Curve
* ``&#39;cles&#39;``: Common Language Effect Size</code></pre><p><strong>Returns</strong></p><p>ef : float64     Effect size</p><p><strong>See Also</strong></p><p>convert<em>effsize : Conversion between effect sizes. compute</em>effsize<em>from</em>t : Convert a T-statistic to an effect size.</p><p><strong>Notes</strong></p><p>Missing values are automatically removed from the data. If <span>$x$</span> and <span>$y$</span> are paired, the entire row is removed.</p><p>If <span>$x$</span> and <span>$y$</span> are independent, the Cohen :math:<code>d</code> is:</p><p>.. math::</p><pre><code class="language-none">d = \frac{\overline{X} - \overline{Y}}
{\sqrt{\frac{(n_{1} - 1)\sigma_{1}^{2} + (n_{2} - 1)
\sigma_{2}^{2}}{n1 + n2 - 2}}}</code></pre><p>If <span>$x$</span> and <span>$y$</span> are paired, the Cohen :math:<code>d_{avg}</code> is computed:</p><p>.. math::</p><pre><code class="language-none">d_{avg} = \frac{\overline{X} - \overline{Y}}
{\sqrt{\frac{(\sigma_1^2 + \sigma_2^2)}{2}}}</code></pre><p>The Cohen’s d is a biased estimate of the population effect size, especially for small samples (n &lt; 20). It is often preferable to use the corrected Hedges :math:<code>g</code> instead:</p><p>.. math:: g = d \times (1 - \frac{3}{4(n<em>1 + n</em>2) - 9})</p><p>The Glass :math:<code>\delta</code> is calculated using the group with the lowest variance as the control group:</p><p>.. math::</p><pre><code class="language-none">\delta = \frac{\overline{X} -
\overline{Y}}{\sigma^2_{\text{control}}}</code></pre><p>The common language effect size is the proportion of pairs where <span>$x$</span> is higher than <span>$y$</span> (calculated with a brute-force approach where each observation of <span>$x$</span> is paired to each observation of <span>$y$</span>, see <code>Pingouin.wilcoxon</code> for more details):</p><p>.. math:: \text{CL} = P(X &gt; Y) + .5 \times P(X = Y)</p><p>For other effect sizes, Pingouin will first calculate a Cohen :math:<code>d</code> and then use the <code>Pingouin.convert_effsize</code> to convert to the desired effect size.</p><p><strong>References</strong></p><ul><li><p>Lakens, D., 2013. Calculating and reporting effect sizes to   facilitate cumulative science: a practical primer for t-tests and   ANOVAs. Front. Psychol. 4, 863. https://doi.org/10.3389/fpsyg.2013.00863</p></li><li><p>Cumming, Geoff. Understanding the new statistics: Effect sizes,   confidence intervals, and meta-analysis. Routledge, 2013.</p></li><li><p>https://osf.io/vbdah/</p></li></ul><p><strong>Examples</strong></p><ol><li>Cohen d from two independent samples.</li></ol><blockquote><blockquote><blockquote><p>x = [1, 2, 3, 4] y = [3, 4, 5, 6, 7] Pingouin.compute_effsize(x, y, paired=false, eftype=&quot;cohen&quot;)</p></blockquote></blockquote></blockquote><p>-1.707825127659933</p><p>The sign of the Cohen d will be opposite if we reverse the order of <span>$x$</span> and <span>$y$</span>:</p><blockquote><blockquote><blockquote><p>Pingouin.compute_effsize(y, x, paired=false, eftype=&quot;cohen&quot;)</p></blockquote></blockquote></blockquote><p>1.707825127659933</p><ol><li>Hedges g from two paired samples.</li></ol><blockquote><blockquote><blockquote><p>x = [1, 2, 3, 4, 5, 6, 7] y = [1, 3, 5, 7, 9, 11, 13] Pingouin.compute_effsize(x, y, paired=true, eftype=&quot;hedges&quot;)</p></blockquote></blockquote></blockquote><p>-0.8222477210374874</p><ol><li>Glass delta from two independent samples. The group with the lowest</li></ol><p>variance will automatically be selected as the control.</p><blockquote><blockquote><blockquote><p>Pingouin.compute_effsize(x, y, paired=false, eftype=&quot;glass&quot;)</p></blockquote></blockquote></blockquote><p>-1.3887301496588271</p><ol><li>Common Language Effect Size.</li></ol><blockquote><blockquote><blockquote><p>Pingouin.compute_effsize(x, y, eftype=&quot;cles&quot;)</p></blockquote></blockquote></blockquote><p>0.2857142857142857</p><p>In other words, there are ~29% of pairs where <span>$x$</span> is higher than <span>$y$</span>, which means that there are ~71% of pairs where <span>$x$</span> is <em>lower</em> than <span>$y$</span>. This can be easily verified by changing the order of <span>$x$</span> and <span>$y$</span>:</p><blockquote><blockquote><blockquote><p>Pingouin.compute_effsize(y, x, eftype=&quot;cles&quot;)</p></blockquote></blockquote></blockquote><p>0.7142857142857143</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/effsize.jl#L20-L151">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.compute_effsize-Tuple{Array{var&quot;#s29&quot;,N} where N where var&quot;#s29&quot;&lt;:Number,Array{var&quot;#s28&quot;,N} where N where var&quot;#s28&quot;&lt;:Number}" href="#Pingouin.compute_effsize-Tuple{Array{var&quot;#s29&quot;,N} where N where var&quot;#s29&quot;&lt;:Number,Array{var&quot;#s28&quot;,N} where N where var&quot;#s28&quot;&lt;:Number}"><code>Pingouin.compute_effsize</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Calculate effect size between two set of observations.</p><p><strong>Parameters</strong></p><p>x : array     First set of observations. y : array     Second set of observations. paired : boolean     If True, uses Cohen d-avg formula to correct for repeated measurements     (see Notes). eftype : string     Desired output effect size.     Available methods are:</p><pre><code class="language-none">* ``&#39;none&#39;``: no effect size
* ``&#39;cohen&#39;``: Unbiased Cohen d
* ``&#39;hedges&#39;``: Hedges g
* ``&#39;glass&#39;``: Glass delta
* ``&#39;r&#39;``: correlation coefficient
* ``&#39;eta-square&#39;``: Eta-square
* ``&#39;odds-ratio&#39;``: Odds ratio
* ``&#39;auc&#39;``: Area Under the Curve
* ``&#39;cles&#39;``: Common Language Effect Size</code></pre><p><strong>Returns</strong></p><p>ef : float64     Effect size</p><p><strong>See Also</strong></p><p>convert<em>effsize : Conversion between effect sizes. compute</em>effsize<em>from</em>t : Convert a T-statistic to an effect size.</p><p><strong>Notes</strong></p><p>Missing values are automatically removed from the data. If <span>$x$</span> and <span>$y$</span> are paired, the entire row is removed.</p><p>If <span>$x$</span> and <span>$y$</span> are independent, the Cohen :math:<code>d</code> is:</p><p>.. math::</p><pre><code class="language-none">d = \frac{\overline{X} - \overline{Y}}
{\sqrt{\frac{(n_{1} - 1)\sigma_{1}^{2} + (n_{2} - 1)
\sigma_{2}^{2}}{n1 + n2 - 2}}}</code></pre><p>If <span>$x$</span> and <span>$y$</span> are paired, the Cohen :math:<code>d_{avg}</code> is computed:</p><p>.. math::</p><pre><code class="language-none">d_{avg} = \frac{\overline{X} - \overline{Y}}
{\sqrt{\frac{(\sigma_1^2 + \sigma_2^2)}{2}}}</code></pre><p>The Cohen’s d is a biased estimate of the population effect size, especially for small samples (n &lt; 20). It is often preferable to use the corrected Hedges :math:<code>g</code> instead:</p><p>.. math:: g = d \times (1 - \frac{3}{4(n<em>1 + n</em>2) - 9})</p><p>The Glass :math:<code>\delta</code> is calculated using the group with the lowest variance as the control group:</p><p>.. math::</p><pre><code class="language-none">\delta = \frac{\overline{X} -
\overline{Y}}{\sigma^2_{\text{control}}}</code></pre><p>The common language effect size is the proportion of pairs where <span>$x$</span> is higher than <span>$y$</span> (calculated with a brute-force approach where each observation of <span>$x$</span> is paired to each observation of <span>$y$</span>, see <code>Pingouin.wilcoxon</code> for more details):</p><p>.. math:: \text{CL} = P(X &gt; Y) + .5 \times P(X = Y)</p><p>For other effect sizes, Pingouin will first calculate a Cohen :math:<code>d</code> and then use the <code>Pingouin.convert_effsize</code> to convert to the desired effect size.</p><p><strong>References</strong></p><ul><li><p>Lakens, D., 2013. Calculating and reporting effect sizes to   facilitate cumulative science: a practical primer for t-tests and   ANOVAs. Front. Psychol. 4, 863. https://doi.org/10.3389/fpsyg.2013.00863</p></li><li><p>Cumming, Geoff. Understanding the new statistics: Effect sizes,   confidence intervals, and meta-analysis. Routledge, 2013.</p></li><li><p>https://osf.io/vbdah/</p></li></ul><p><strong>Examples</strong></p><ol><li>Cohen d from two independent samples.</li></ol><blockquote><blockquote><blockquote><p>x = [1, 2, 3, 4] y = [3, 4, 5, 6, 7] Pingouin.compute_effsize(x, y, paired=false, eftype=&quot;cohen&quot;)</p></blockquote></blockquote></blockquote><p>-1.707825127659933</p><p>The sign of the Cohen d will be opposite if we reverse the order of <span>$x$</span> and <span>$y$</span>:</p><blockquote><blockquote><blockquote><p>Pingouin.compute_effsize(y, x, paired=false, eftype=&quot;cohen&quot;)</p></blockquote></blockquote></blockquote><p>1.707825127659933</p><ol><li>Hedges g from two paired samples.</li></ol><blockquote><blockquote><blockquote><p>x = [1, 2, 3, 4, 5, 6, 7] y = [1, 3, 5, 7, 9, 11, 13] Pingouin.compute_effsize(x, y, paired=true, eftype=&quot;hedges&quot;)</p></blockquote></blockquote></blockquote><p>-0.8222477210374874</p><ol><li>Glass delta from two independent samples. The group with the lowest</li></ol><p>variance will automatically be selected as the control.</p><blockquote><blockquote><blockquote><p>Pingouin.compute_effsize(x, y, paired=false, eftype=&quot;glass&quot;)</p></blockquote></blockquote></blockquote><p>-1.3887301496588271</p><ol><li>Common Language Effect Size.</li></ol><blockquote><blockquote><blockquote><p>Pingouin.compute_effsize(x, y, eftype=&quot;cles&quot;)</p></blockquote></blockquote></blockquote><p>0.2857142857142857</p><p>In other words, there are ~29% of pairs where <span>$x$</span> is higher than <span>$y$</span>, which means that there are ~71% of pairs where <span>$x$</span> is <em>lower</em> than <span>$y$</span>. This can be easily verified by changing the order of <span>$x$</span> and <span>$y$</span>:</p><blockquote><blockquote><blockquote><p>Pingouin.compute_effsize(y, x, eftype=&quot;cles&quot;)</p></blockquote></blockquote></blockquote><p>0.7142857142857143</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/effsize.jl#L20-L151">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.compute_effsize_from_t-Tuple{Float64}" href="#Pingouin.compute_effsize_from_t-Tuple{Float64}"><code>Pingouin.compute_effsize_from_t</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Compute effect size from a T-value.</p><p><strong>Parameters</strong></p><p>tval : float     T-value nx, ny : int, optional     Group sample sizes. N : int, optional     Total sample size (will not be used if nx and ny are specified) eftype : string, optional     desired output effect size</p><p><strong>Returns</strong></p><p>ef : float     Effect size</p><p><strong>See Also</strong></p><p>compute<em>effsize : Calculate effect size between two set of observations. convert</em>effsize : Conversion between effect sizes.</p><p><strong>Notes</strong></p><p>If both nx and ny are specified, the formula to convert from <em>t</em> to <em>d</em> is:</p><p>.. math:: d = t * \sqrt{\frac{1}{n<em>x} + \frac{1}{n</em>y}}</p><p>If only N (total sample size) is specified, the formula is:</p><p>.. math:: d = \frac{2t}{\sqrt{N}}</p><p><strong>Examples</strong></p><ol><li>Compute effect size from a T-value when both sample sizes are known.</li></ol><blockquote><blockquote><blockquote><p>tval, nx, ny = 2.90, 35, 25 d = Pingouin.compute<em>effsize</em>from_t(tval, nx=nx, ny=ny, eftype=&quot;cohen&quot;)</p></blockquote></blockquote></blockquote><p>0.7593982580212534</p><ol><li>Compute effect size when only total sample size is known (nx+ny)</li></ol><blockquote><blockquote><blockquote><p>tval, N = 2.90, 60 d = Pingouin.compute<em>effsize</em>from_t(tval, N=N, eftype=&quot;cohen&quot;)</p></blockquote></blockquote></blockquote><p>0.7487767802667672</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/effsize.jl#L367-L414">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.compute_esci-Tuple{}" href="#Pingouin.compute_esci-Tuple{}"><code>Pingouin.compute_esci</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Parametric confidence intervals around a Cohen d or a correlation coefficient.</p><p><strong>Parameters</strong></p><p>stat : float     Original effect size. Must be either a correlation coefficient or a     Cohen-type effect size (Cohen d or Hedges g). nx, ny : int     Length of vector x and y. paired : bool     Indicates if the effect size was estimated from a paired sample.     This is only relevant for cohen or hedges effect size. eftype : string     Effect size type. Must be <span>$&#39;r&#39;$</span> (correlation) or <span>$&#39;cohen&#39;$</span>     (Cohen d or Hedges g). confidence : float     Confidence level (0.95 = 95%) decimals : int     Number of rounded decimals.</p><p><strong>Returns</strong></p><p>ci : array     Desired converted effect size</p><p><strong>Notes</strong></p><p>To compute the parametric confidence interval around a <strong>Pearson r correlation</strong> coefficient, one must first apply a Fisher&#39;s r-to-z transformation:</p><p>.. math:: z = 0.5 \cdot \ln \frac{1 + r}{1 - r} = \text{arctanh}(r)</p><p>and compute the standard deviation:</p><p>.. math:: \sigma = \frac{1}{\sqrt{n - 3}}</p><p>where :math:<code>n</code> is the sample size.</p><p>The lower and upper confidence intervals - <em>in z-space</em> - are then given by:</p><p>.. math:: \text{ci}_z = z \pm \text{crit} \cdot \sigma</p><p>where :math:<code>\text{crit}</code> is the critical value of the normal distribution corresponding to the desired confidence level (e.g. 1.96 in case of a 95% confidence interval).</p><p>These confidence intervals can then be easily converted back to <em>r-space</em>:</p><p>.. math::</p><pre><code class="language-none">\text{ci}_r = \frac{\exp(2 \cdot \text{ci}_z) - 1}
{\exp(2 \cdot \text{ci}_z) + 1} = \text{tanh}(\text{ci}_z)</code></pre><p>A formula for calculating the confidence interval for a <strong>Cohen d effect size</strong> is given by Hedges and Olkin (1985, p86). If the effect size estimate from the sample is :math:<code>d</code>, then it follows a T distribution with standard deviation:</p><p>.. math::</p><pre><code class="language-none">\sigma = \sqrt{\frac{n_x + n_y}{n_x \cdot n_y} +
\frac{d^2}{2 (n_x + n_y)}}</code></pre><p>where :math:<code>n_x</code> and :math:<code>n_y</code> are the sample sizes of the two groups.</p><p>In one-sample test or paired test, this becomes:</p><p>.. math::</p><pre><code class="language-none">\sigma = \sqrt{\frac{1}{n_x} + \frac{d^2}{2 n_x}}</code></pre><p>The lower and upper confidence intervals are then given by:</p><p>.. math:: \text{ci}_d = d \pm \text{crit} \cdot \sigma</p><p>where :math:<code>\text{crit}</code> is the critical value of the T distribution corresponding to the desired confidence level.</p><p><strong>References</strong></p><ul><li><p>https://en.wikipedia.org/wiki/Fisher_transformation</p></li><li><p>Hedges, L., and Ingram Olkin. &quot;Statistical models for meta-analysis.&quot;   (1985).</p></li><li><p>http://www.leeds.ac.uk/educol/documents/00002182.htm</p></li><li><p>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5133225/</p></li></ul><p><strong>Examples</strong></p><ol><li>Confidence interval of a Pearson correlation coefficient</li></ol><blockquote><blockquote><blockquote><p>x = [3, 4, 6, 7, 5, 6, 7, 3, 5, 4, 2] y = [4, 6, 6, 7, 6, 5, 5, 2, 3, 4, 1] nx, ny = length(x), length(y) stat = Pingouin.compute_effsize(x, y, eftype=&quot;r&quot;)</p></blockquote></blockquote></blockquote><p>0.7468280049029223</p><blockquote><blockquote><blockquote><p>ci = Pingouin.compute_esci(stat=stat, nx=nx, ny=ny, eftype=&quot;r&quot;)</p></blockquote></blockquote></blockquote><p>2-element Array{Float64,1}:  0.27  0.93</p><ol><li>Confidence interval of a Cohen d</li></ol><blockquote><blockquote><blockquote><p>stat = Pingouin.compute_effsize(x, y, eftype=&quot;cohen&quot;)</p></blockquote></blockquote></blockquote><p>0.1537753990658328</p><blockquote><blockquote><blockquote><p>ci = Pingouin.compute_esci(stat=stat, nx=nx, ny=ny, eftype=&quot;cohen&quot;, decimals=3)</p></blockquote></blockquote></blockquote><p>2-element Array{Float64,1}:  -0.737   1.045</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/effsize.jl#L436-L551">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.convert_effsize-Tuple{Float64,String,String}" href="#Pingouin.convert_effsize-Tuple{Float64,String,String}"><code>Pingouin.convert_effsize</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Conversion between effect sizes.</p><p><strong>Parameters</strong></p><p>ef : float64     Original effect size. input<em>type : string     Effect size type of ef. Must be <span>$&#39;r&#39;$</span> or <span>$&#39;d&#39;$</span>. output</em>type : string     Desired effect size type. Available methods are:</p><pre><code class="language-none">* ``&#39;cohen&#39;``: Unbiased Cohen d
* ``&#39;hedges&#39;``: Hedges g
* ``&#39;eta-square&#39;``: Eta-square
* ``&#39;odds-ratio&#39;``: Odds ratio
* ``&#39;AUC&#39;``: Area Under the Curve
* ``&#39;none&#39;``: pass-through (return ``ef``)</code></pre><p>nx, ny : int, optional     Length of vector x and y. Required to convert to Hedges g.</p><p><strong>Returns</strong></p><p>ef : float     Desired converted effect size</p><p><strong>See Also</strong></p><p>compute<em>effsize : Calculate effect size between two set of observations. compute</em>effsize<em>from</em>t : Convert a T-statistic to an effect size.</p><p><strong>Notes</strong></p><p>The formula to convert <strong>r</strong> to <strong>d</strong> is given in [1]_:</p><p>.. math:: d = \frac{2r}{\sqrt{1 - r^2}}</p><p>The formula to convert <strong>d</strong> to <strong>r</strong> is given in [2]_:</p><p>.. math::</p><pre><code class="language-none">r = \frac{d}{\sqrt{d^2 + \frac{(n_x + n_y)^2 - 2(n_x + n_y)}
{n_xn_y}}}</code></pre><p>The formula to convert <strong>d</strong> to :math:<code>\eta^2</code> is given in [3]_:</p><p>.. math:: \eta^2 = \frac{(0.5 d)^2}{1 + (0.5 d)^2}</p><p>The formula to convert <strong>d</strong> to an odds-ratio is given in [4]_:</p><p>.. math:: \text{OR} = \exp (\frac{d \pi}{\sqrt{3}})</p><p>The formula to convert <strong>d</strong> to area under the curve is given in [5]_:</p><p>.. math:: \text{AUC} = \mathcal{N}_{cdf}(\frac{d}{\sqrt{2}})</p><p><strong>References</strong></p><p>.. [1] Rosenthal, Robert. &quot;Parametric measures of effect size.&quot;     The handbook of research synthesis 621 (1994): 231-244.</p><p>.. [2] McGrath, Robert E., and Gregory J. Meyer. &quot;When effect sizes     disagree: the case of r and d.&quot; Psychological methods 11.4 (2006): 386.</p><p>.. [3] Cohen, Jacob. &quot;Statistical power analysis for the behavioral     sciences. 2nd.&quot; (1988).</p><p>.. [4] Borenstein, Michael, et al. &quot;Effect sizes for continuous data.&quot;     The handbook of research synthesis and meta-analysis 2 (2009): 221-235.</p><p>.. [5] Ruscio, John. &quot;A probability-based measure of effect size:     Robustness to base rates and other factors.&quot; Psychological methods 1     3.1 (2008): 19.</p><p><strong>Examples</strong></p><ol><li>Convert from Cohen d to eta-square</li></ol><blockquote><blockquote><blockquote><p>d = .45 eta = Pingouin.convert_effsize(d, &quot;cohen&quot;, &quot;eta-square&quot;)</p></blockquote></blockquote></blockquote><p>0.048185603807257595</p><ol><li>Convert from Cohen d to Hegdes g (requires the sample sizes of each  group)</li></ol><blockquote><blockquote><blockquote><p>Pingouin.convert_effsize(.45, &quot;cohen&quot;, &quot;hedges&quot;, nx=10, ny=10)</p></blockquote></blockquote></blockquote><p>0.4309859154929578</p><ol><li>Convert Pearson r to Cohen d</li></ol><blockquote><blockquote><blockquote><p>r = 0.40 d = Pingouin.convert_effsize(r, &quot;r&quot;, &quot;cohen&quot;)</p></blockquote></blockquote></blockquote><p>0.8728715609439696</p><ol><li>Reverse operation: convert Cohen d to Pearson r</li></ol><blockquote><blockquote><blockquote><p>Pingouin.convert_effsize(d, &quot;cohen&quot;, &quot;r&quot;)</p></blockquote></blockquote></blockquote><p>0.4000000000000001</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/effsize.jl#L212-L311">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.bayesfactor_binom" href="#Pingouin.bayesfactor_binom"><code>Pingouin.bayesfactor_binom</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">bayesfactor_binom(k, n, p)</code></pre><p>Bayes factor of a binomial test with <span>$k$</span> successes, <span>$n$</span> trials and base probability <span>$p$</span>.</p><p><strong>Arguments</strong></p><ul><li><code>k::Int64</code>: Number of successes.</li><li><code>n::Int64</code>: Number of trials.</li><li><code>p::Float64</code>: Base probability of success (range from 0 to 1).</li></ul><p><strong>Returns</strong></p><ul><li><code>binom_bf::Float64</code>: The Bayes Factor quantifies the evidence in favour of the alternative hypothesis, where the null hypothesis is that the random variable is binomially distributed with base probability <span>$p$</span>.</li></ul><p><strong>See also</strong></p><ul><li><a href="#Pingouin.bayesfactor_pearson-Tuple{Float64,Int64}"><code>bayesfactor_pearson</code></a>: Bayes Factor of a correlation</li><li><a href="#Pingouin.bayesfactor_ttest"><code>bayesfactor_ttest</code></a>: Bayes Factor of a T-test</li></ul><p><strong>Notes</strong></p><p>Adapted from a Matlab code found at https://github.com/anne-urai/Tools/blob/master/stats/BayesFactors/binombf.m The Bayes Factor is given by the formula below:</p><div>\[BF_{10} = \frac{\int_0^1 \binom{n}{k}g^k(1-g)^{n-k}} {\binom{n}{k} p^k (1-p)^{n-k}}\]</div><p><strong>References</strong></p><ul><li>http://pcl.missouri.edu/bf-binomial</li><li>https://en.wikipedia.org/wiki/Bayes_factor</li></ul><p><strong>Examples</strong></p><p>We want to determine if a coin is fair. After tossing the coin 200 times in a row, we report 115 heads (hereafter referred to as &quot;successes&quot;) and 85 tails (&quot;failures&quot;). The Bayes Factor can be easily computed using Pingouin:</p><pre><code class="language-julia-repl">julia&gt; using Pingouin
julia&gt; bf = Pingouin.bayesfactor_binom(115, 200, 0.5)
julia&gt; # Note that Pingouin returns the BF-alt by default.
julia&gt; # BF-null is simply 1 / BF-alt
julia&gt; print(&quot;BF-null: &quot;, 1 / bf, &quot;; BF-alt: &quot;, bf)
BF-null: 1.197134330237549; BF-alt: 0.8353281455069195</code></pre><p>Since the Bayes Factor of the null hypothesis (&quot;the coin is fair&quot;) is higher than the Bayes Factor of the alternative hypothesis (&quot;the coin is not fair&quot;), we can conclude that there is more evidence to support the fact that the coin is indeed fair. However, the strength of the evidence in favor of the null hypothesis (1.197) is &quot;barely worth mentionning&quot; according to Jeffreys&#39;s rule of thumb.</p><p>Interestingly, a frequentist alternative to this test would give very different results. It can be performed using the <code>SciPy.stats.binom_test</code> function:</p><pre><code class="language-julia-repl">julia&gt; using SciPy
julia&gt; pval = SciPy.stats.binom_test(115, 200, p=0.5)
julia&gt; round.(pval, digits=5)
0.04004</code></pre><p>The binomial test rejects the null hypothesis that the coin is fair at the 5% significance level (p=0.04). Thus, whereas a frequentist hypothesis test would yield significant results at the 5% significance level, the Bayes factor does not find any evidence that the coin is unfair. Last example using a different base probability of successes</p><pre><code class="language-julia-repl">julia&gt; bf = Pingouin.bayesfactor_binom(100, 1000, 0.1)
julia&gt; print(&quot;Bayes Factor: &quot;, round.(bf, digits=3))
Bayes Factor: 0.024</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/bayesian.jl#L6-L84">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.bayesfactor_pearson-Tuple{Float64,Int64}" href="#Pingouin.bayesfactor_pearson-Tuple{Float64,Int64}"><code>Pingouin.bayesfactor_pearson</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">bayesfactor_pearson(r, n[, tail, method, kappa])</code></pre><p>Bayes Factor of a Pearson correlation.</p><p><strong>Arguments</strong></p><ul><li><code>r::Float64</code>: Pearson correlation coefficient.</li><li><code>n::Int64</code>: Sample size.</li><li><code>tail::String</code>: Tail of the alternative hypothesis. Can be <em>&#39;two-sided&#39;</em>, <em>&#39;one-sided&#39;</em>, <em>&#39;greater&#39;</em> or <em>&#39;less&#39;</em>. <em>&#39;greater&#39;</em> corresponds to a positive correlation, <em>&#39;less&#39;</em> to a negative correlation. If <em>&#39;one-sided&#39;</em>, the directionality is inferred based on the <span>$r$</span> value (= <em>&#39;greater&#39;</em> if <span>$r$</span> &gt; 0, <em>&#39;less&#39;</em> if <span>$r$</span> &lt; 0).</li><li><code>method::String</code>: Method to compute the Bayes Factor. Can be <em>&#39;ly&#39;</em> (default) or <em>&#39;wetzels&#39;</em>. The former has an exact analytical solution, while the latter requires integral solving (and is therefore slower). <em>&#39;wetzels&#39;</em> was the default in Pingouin &lt;= 0.2.5. See Notes for details.</li><li><code>kappa::Float64</code>: Kappa factor. This is sometimes called the <em>rscale</em> parameter, and</li></ul><p>is only used when <span>$method$</span> is <em>&#39;ly&#39;</em>.</p><p><strong>Returns</strong></p><ul><li><code>bf::Float64</code>: Bayes Factor (BF10).</li></ul><p>The Bayes Factor quantifies the evidence in favour of the alternative hypothesis.</p><p><strong>See also</strong></p><ul><li><a href="@ref"><code>corr</code></a>: (Robust) correlation between two variables,</li><li><a href="@ref"><code>pairwise_corr</code></a>: Pairwise correlation between columns of a pandas DataFrame,</li><li><a href="#Pingouin.bayesfactor_ttest"><code>bayesfactor_ttest</code></a>: Bayes Factor of a T-test,</li><li><a href="#Pingouin.bayesfactor_binom"><code>bayesfactor_binom</code></a>: Bayes Factor of a binomial test.</li></ul><p><strong>Notes</strong></p><p>To compute the Bayes Factor directly from the raw data, use the <code>pingouin.corr</code> function. The two-sided <strong>Wetzels Bayes Factor</strong> (also called <em>JZS Bayes Factor</em>) is calculated using the equation 13 and associated R code of [1]:</p><div>\[\text{BF}_{10}(n, r) = \frac{\sqrt{n/2}}{\gamma(1/2)}* \int_{0}^{\infty}e((n-2)/2)* log(1+g)+(-(n-1)/2)log(1+(1-r^2)*g)+(-3/2)log(g)-n/2g\]</div><p>where <span>$n$</span> is the sample size, <span>$r$</span> is the Pearson correlation coefficient and <span>$g$</span> is is an auxiliary variable that is integrated out numerically. Since the Wetzels Bayes Factor requires solving an integral, it is slower than the analytical solution described below. The two-sided <strong>Ly Bayes Factor</strong> (also called <em>Jeffreys exact Bayes Factor</em>) is calculated using equation 25 of [2]:</p><div>\[\text{BF}_{10;k}(n, r) = \frac{2^{\frac{k-2}{k}}\sqrt{\pi}} {\beta(\frac{1}{k}, \frac{1}{k})} \cdot \frac{\Gamma(\frac{2+k(n-1)}{2k})}{\Gamma(\frac{2+nk}{2k})} \cdot 2F_1(\frac{n-1}{2}, \frac{n-1}{2}, \frac{2+nk}{2k}, r^2)\]</div><p>The one-sided version is described in eq. 27 and 28 of Ly et al, 2016. Please take note that the one-sided test requires the <a href="http://mpmath.org/">mpmath</a> package. Results have been validated against JASP and the BayesFactor R package.</p><p><strong>References</strong></p><p>[1] Ly, A., Verhagen, J. &amp; Wagenmakers, E.-J. Harold Jeffreys’s default Bayes factor hypothesis tests: Explanation, extension, and application in psychology. J. Math. Psychol. 72, 19–32 (2016).</p><p>[2] Wetzels, R. &amp; Wagenmakers, E.-J. A default Bayesian hypothesis test for correlations and partial correlations. Psychon. Bull. Rev. 19, 1057–1064 (2012).</p><p><strong>Examples</strong></p><p>Bayes Factor of a Pearson correlation</p><pre><code class="language-julia-repl">julia&gt; using Pingouin
julia&gt; r, n = 0.6, 20
julia&gt; bf = Pingouin.bayesfactor_pearson(r, n)
julia&gt; print(&quot;Bayes Factor: &quot;, round.(bf, digits=3))
Bayes Factor: 10.634</code></pre><p>Compare to Wetzels method:</p><pre><code class="language-julia-repl">julia&gt; bf = Pingouin.bayesfactor_pearson(r, n,
                                    tail=&quot;two-sided&quot;,
                                    method=&quot;wetzels&quot;,
                                    kappa=1.)
julia&gt; print(&quot;Bayes Factor: &quot;, round.(bf, digits=3))
Bayes Factor: 8.221</code></pre><p>One-sided test</p><pre><code class="language-julia-repl">julia&gt; bf10pos = Pingouin.bayesfactor_pearson(r, n, 
                                         tail=&quot;one-sided&quot;,
                                         method=&quot;ly&quot;,
                                         kappa=1.0)
julia&gt; bf10neg = Pingouin.bayesfactor_pearson(r, n,
                                         tail=&quot;less&quot;,
                                         method=&quot;ly&quot;,
                                         kappa=1.0)
julia&gt; print(&quot;BF-pos: &quot;, round.(bf10pos, digits=3),&quot; BF-neg: &quot;, round.(bf10neg, digits=3))
BF-pos: 21.185, BF-neg: 0.082</code></pre><p>We can also only pass <code>tail=&#39;one-sided&#39;</code> and Pingouin will automatically infer the directionality of the test based on the <span>$r$</span> value.</p><pre><code class="language-julia-repl">julia&gt; print(&quot;BF: &quot;, round.(bayesfactor_pearson(r, n, tail=&quot;one-sided&quot;), digits=3))
BF: 21.185</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/bayesian.jl#L100-L205">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.bayesfactor_ttest" href="#Pingouin.bayesfactor_ttest"><code>Pingouin.bayesfactor_ttest</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">bayesfactor_ttest(t, nx[, ny, paired, tail, r])</code></pre><p>nx::Int64, ny::Union{Int64,Nothing}=nothing; paired::Bool=false, tail::String=&quot;two-sided&quot;, r::Float64=.707)::Float64</p><p>Bayes Factor of a T-test.</p><p><strong>Parameters</strong></p><ul><li><code>t::Float64</code>: T-value of the T-test</li><li><code>nx::Int64</code>: Sample size of first group</li><li><code>ny::Int64</code>: Sample size of second group (only needed in case of an independent two-sample T-test)</li><li><code>paired::Bool</code>: boolean Specify whether the two observations are related (i.e. repeated measures) or independent.</li><li><code>tail::String</code>: string Specify whether the test is <code>&#39;one-sided&#39;</code> or <code>&#39;two-sided&#39;</code>. Can also be <code>&#39;greater&#39;</code> or <code>&#39;less&#39;</code> to specify the direction of the test.</li></ul><p><strong>WARNING</strong>: One-sided Bayes Factor (BF) are simply obtained by doubling the two-sided BF, which is not exactly the same behavior as R or JASP. Be extra careful when interpretating one-sided BF, and if you can, always double-check your results.</p><ul><li><code>r::Float64</code>: Cauchy scale factor. Smaller values of <span>$r$</span> (e.g. 0.5), may be appropriate when small effect sizes are expected a priori; larger values of <span>$r$</span> are appropriate when large effect sizes are expected (Rouder et al 2009). The default is <span>$\sqrt{2} / 2 \approx 0.707$</span>.</li></ul><p><strong>Returns</strong></p><ul><li><code>bf::Float64</code>: Scaled Jeffrey-Zellner-Siow (JZS) Bayes Factor (BF10). The Bayes Factor quantifies the evidence in favour of the alternative hypothesis.</li></ul><p><strong>See also</strong></p><ul><li><a href="@ref"><code>ttest</code></a>: T-test</li><li><a href="@ref"><code>pairwise_ttest</code></a>: Pairwise T-tests</li><li><a href="#Pingouin.bayesfactor_pearson-Tuple{Float64,Int64}"><code>bayesfactor_pearson</code></a>: Bayes Factor of a correlation</li><li><a href="#Pingouin.bayesfactor_binom"><code>bayesfactor_binom</code></a>: Bayes Factor of a binomial test</li></ul><p><strong>Notes</strong></p><p>Adapted from a Matlab code found at https://github.com/anne-urai/Tools/tree/master/stats/BayesFactors If you would like to compute the Bayes Factor directly from the raw data instead of from the T-value, use the <a href="@ref"><code>pingouin.ttest</code></a> function. The JZS Bayes Factor is approximated using the formula described in ref [1]:</p><div>\[\text{BF}_{10} = \frac{\int_{0}^{\infty}(1 + Ngr^2)^{-1/2} (1 + \frac{t^2}{v(1 + Ngr^2)})^{-(v+1) / 2}(2\pi)^{-1/2}g^ {-3/2}e^{-1/2g}}{(1 + \frac{t^2}{v})^{-(v+1) / 2}}\]</div><p>where <span>$t$</span> is the T-value, <span>$v$</span> the degrees of freedom, <span>$N$</span> the sample size, <span>$r$</span> the Cauchy scale factor (= prior on effect size) and <span>$g$</span> is is an auxiliary variable that is integrated out numerically. Results have been validated against JASP and the BayesFactor R package.</p><p><strong>References</strong></p><p>[1] Rouder, J.N., Speckman, P.L., Sun, D., Morey, R.D., Iverson, G.,</p><ol><li>Bayesian t tests for accepting and rejecting the null hypothesis.</li></ol><p>Psychon. Bull. Rev. 16, 225–237. https://doi.org/10.3758/PBR.16.2.225</p><p><strong>Examples</strong></p><ol><li>Bayes Factor of an independent two-sample T-test</li></ol><pre><code class="language-julia-repl">julia&gt; bf = Pingouin.bayesfactor_ttest(3.5, 20, 20)
julia&gt; print(&quot;Bayes Factor: &quot;, round.(bf, digits=3), &quot;(two-sample independent)&quot;)
Bayes Factor: 26.743 (two-sample independent)</code></pre><ol><li>Bayes Factor of a paired two-sample T-test</li></ol><pre><code class="language-julia-repl">julia&gt; bf = Pingouin.bayesfactor_ttest(3.5, 20, 20, paired=true)
julia&gt; print(&quot;Bayes Factor: &quot;, round.(bf, digits=3), &quot;(two-sample paired)&quot;)
Bayes Factor: 17.185 (two-sample paired)</code></pre><ol><li>Bayes Factor of an one-sided one-sample T-test</li></ol><pre><code class="language-julia-repl">julia&gt; bf = Pingouin.bayesfactor_ttest(3.5, 20, tail=&quot;one-sided&quot;)
julia&gt; print(&quot;Bayes Factor: &quot;, round.(bf, digits=3), &quot;(one-sample)&quot;)
Bayes Factor: 34.369 (one-sample)</code></pre><ol><li>Now specifying the direction of the test</li></ol><pre><code class="language-julia-repl">julia&gt; tval = -3.5
julia&gt; bf_greater = Pingouin.bayesfactor_ttest(tval, 20, tail=&quot;greater&quot;)
julia&gt; bf_less = Pingouin.bayesfactor_ttest(tval, 20, tail=&quot;less&quot;)
julia&gt; print(&quot;BF10-greater: &quot;, round.(bf_greater, digits=3), &quot; | BF10-less: &quot;, round.(bf_less, digits=3))
BF10-greater: 0.029 | BF10-less: 34.369</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/clementpoiret/Pingouin.jl/blob/c04dc0f1296f8334354b62f40d9f57020b3337c0/src/bayesian.jl#L276-L369">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 26 October 2020 10:49">Monday 26 October 2020</span>. Using Julia version 1.5.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
