<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Pingouin.jl Documentation · Pingouin</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">Pingouin</span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Pingouin.jl Documentation</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Pingouin.jl Documentation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Pingouin.jl Documentation</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/anirudhacharya/Pingouin.jl/blob/master/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Pingouin.jl-Documentation"><a class="docs-heading-anchor" href="#Pingouin.jl-Documentation">Pingouin.jl Documentation</a><a id="Pingouin.jl-Documentation-1"></a><a class="docs-heading-anchor-permalink" href="#Pingouin.jl-Documentation" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="Pingouin.bayesfactor_binom" href="#Pingouin.bayesfactor_binom"><code>Pingouin.bayesfactor_binom</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Bayes factor of a binomial test with :math:<code>k</code> successes, :math:<code>n</code> trials and base probability :math:<code>p</code>.</p><p><strong>Parameters</strong></p><p>k : int     Number of successes. n : int     Number of trials. p : float     Base probability of success (range from 0 to 1).</p><p><strong>Returns</strong></p><p>binom_bf : float     The Bayes Factor quantifies the evidence in favour of the     alternative hypothesis, where the null hypothesis is that     the random variable is binomially distributed with base probability     :math:<code>p</code>.</p><p><strong>See also</strong></p><p>bayesfactor<em>pearson : Bayes Factor of a correlation bayesfactor</em>ttest : Bayes Factor of a T-test</p><p><strong>Notes</strong></p><p>Adapted from a Matlab code found at https://github.com/anne-urai/Tools/blob/master/stats/BayesFactors/binombf.m The Bayes Factor is given by the formula below: .. math::     BF<em>{10} = \frac{\int</em>0^1 \binom{n}{k}g^k(1-g)^{n-k}}     {\binom{n}{k} p^k (1-p)^{n-k}}</p><p><strong>References</strong></p><ul><li>http://pcl.missouri.edu/bf-binomial</li><li>https://en.wikipedia.org/wiki/Bayes_factor</li></ul><p><strong>Examples</strong></p><p>We want to determine if a coin is fair. After tossing the coin 200 times in a row, we report 115 heads (hereafter referred to as &quot;successes&quot;) and 85 tails (&quot;failures&quot;). The Bayes Factor can be easily computed using Pingouin:</p><blockquote><p>using Pingouin bf = Pingouin.bayesfactor_binom(115, 200, 0.5)</p><h1>Note that Pingouin returns the BF-alt by default.</h1><h1>BF-null is simply 1 / BF-alt</h1><p>print(&quot;BF-null: &quot;, 1 / bf, &quot;; BF-alt: &quot;, bf)</p></blockquote><p>BF-null: 1.197134330237549; BF-alt: 0.8353281455069195</p><p>Since the Bayes Factor of the null hypothesis (&quot;the coin is fair&quot;) is higher than the Bayes Factor of the alternative hypothesis (&quot;the coin is not fair&quot;), we can conclude that there is more evidence to support the fact that the coin is indeed fair. However, the strength of the evidence in favor of the null hypothesis (1.197) is &quot;barely worth mentionning&quot; according to Jeffreys&#39;s rule of thumb.</p><p>Interestingly, a frequentist alternative to this test would give very different results. It can be performed using the <code>SciPy.stats.binom_test</code> function:</p><blockquote><p>using SciPy pval = SciPy.stats.binom_test(115, 200, p=0.5) round.(pval, digits=5)</p></blockquote><p>0.04004</p><p>The binomial test rejects the null hypothesis that the coin is fair at the 5% significance level (p=0.04). Thus, whereas a frequentist hypothesis test would yield significant results at the 5% significance level, the Bayes factor does not find any evidence that the coin is unfair. Last example using a different base probability of successes</p><blockquote><p>bf = Pingouin.bayesfactor_binom(100, 1000, 0.1) print(&quot;Bayes Factor: &quot;, round.(bf, digits=3))</p></blockquote><p>Bayes Factor: 0.024</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/anirudhacharya/Pingouin.jl/blob/e0e43de96f2b5e7106e5ce755b0db920e02b9ae9/src/bayesian.jl#L6-L84">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.bayesfactor_pearson-Tuple{Float64,Int64}" href="#Pingouin.bayesfactor_pearson-Tuple{Float64,Int64}"><code>Pingouin.bayesfactor_pearson</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Bayes Factor of a Pearson correlation.</p><p><strong>Parameters</strong></p><p>r : float     Pearson correlation coefficient. n : int     Sample size. tail : float     Tail of the alternative hypothesis. Can be <em>&#39;two-sided&#39;</em>,     <em>&#39;one-sided&#39;</em>, <em>&#39;greater&#39;</em> or <em>&#39;less&#39;</em>. <em>&#39;greater&#39;</em> corresponds to a     positive correlation, <em>&#39;less&#39;</em> to a negative correlation.     If <em>&#39;one-sided&#39;</em>, the directionality is inferred based on the <span>$r$</span>     value (= <em>&#39;greater&#39;</em> if <span>$r$</span> &gt; 0, <em>&#39;less&#39;</em> if <span>$r$</span> &lt; 0). method : str     Method to compute the Bayes Factor. Can be <em>&#39;ly&#39;</em> (default) or     <em>&#39;wetzels&#39;</em>. The former has an exact analytical solution, while the     latter requires integral solving (and is therefore slower). <em>&#39;wetzels&#39;</em>     was the default in Pingouin &lt;= 0.2.5. See Notes for details. kappa : float     Kappa factor. This is sometimes called the <em>rscale</em> parameter, and     is only used when <span>$method$</span> is <em>&#39;ly&#39;</em>.</p><p><strong>Returns</strong></p><p>bf : float     Bayes Factor (BF10).     The Bayes Factor quantifies the evidence in favour of the alternative     hypothesis.</p><p><strong>See also</strong></p><p>corr : (Robust) correlation between two variables pairwise<em>corr : Pairwise correlation between columns of a pandas DataFrame bayesfactor</em>ttest : Bayes Factor of a T-test bayesfactor_binom : Bayes Factor of a binomial test</p><p><strong>Notes</strong></p><p>To compute the Bayes Factor directly from the raw data, use the <code>pingouin.corr</code> function. The two-sided <strong>Wetzels Bayes Factor</strong> (also called <em>JZS Bayes Factor</em>) is calculated using the equation 13 and associated R code of [1]<em>: .. math::     \text{BF}</em>{10}(n, r) = \frac{\sqrt{n/2}}{\gamma(1/2)}*     \int<em>{0}^{\infty}e((n-2)/2)*     log(1+g)+(-(n-1)/2)log(1+(1-r^2)<em>g)+(-3/2)log(g)-n/2g where :math:<code>n</code> is the sample size, :math:<code>r</code> is the Pearson correlation coefficient and :math:<code>g</code> is is an auxiliary variable that is integrated out numerically. Since the Wetzels Bayes Factor requires solving an integral, it is slower than the analytical solution described below. The two-sided <strong>Ly Bayes Factor</strong> (also called *Jeffreys exact Bayes Factor</em>) is calculated using equation 25 of [2]</em>: .. math::     \text{BF}<em>{10;k}(n, r) = \frac{2^{\frac{k-2}{k}}\sqrt{\pi}}     {\beta(\frac{1}{k}, \frac{1}{k})} \cdot     \frac{\Gamma(\frac{2+k(n-1)}{2k})}{\Gamma(\frac{2+nk}{2k})}     \cdot 2F</em>1(\frac{n-1}{2}, \frac{n-1}{2}, \frac{2+nk}{2k}, r^2) The one-sided version is described in eq. 27 and 28 of Ly et al, 2016. Please take note that the one-sided test requires the <code>mpmath &lt;http://mpmath.org/&gt;</code>_ package. Results have been validated against JASP and the BayesFactor R package.</p><p><strong>References</strong></p><p>.. [1] Ly, A., Verhagen, J. &amp; Wagenmakers, E.-J. Harold Jeffreys’s default    Bayes factor hypothesis tests: Explanation, extension, and    application in psychology. J. Math. Psychol. 72, 19–32 (2016). .. [2] Wetzels, R. &amp; Wagenmakers, E.-J. A default Bayesian hypothesis test    for correlations and partial correlations. Psychon. Bull. Rev. 19,    1057–1064 (2012).</p><p><strong>Examples</strong></p><p>Bayes Factor of a Pearson correlation</p><blockquote><p>using Pingouin r, n = 0.6, 20 bf = Pingouin.bayesfactor_pearson(r, n) print(&quot;Bayes Factor: &quot;, round.(bf, digits=3))</p></blockquote><p>Bayes Factor: 10.634</p><p>Compare to Wetzels method:</p><blockquote><p>bf = Pingouin.bayesfactor_pearson(r, n,</p></blockquote><pre><code class="language-none">                                tail=&quot;two-sided&quot;,
                                method=&quot;wetzels&quot;,
                                kappa=1.)</code></pre><blockquote><p>print(&quot;Bayes Factor: &quot;, round.(bf, digits=3))</p></blockquote><p>Bayes Factor: 8.221</p><p>One-sided test</p><blockquote><p>bf10pos = Pingouin.bayesfactor_pearson(r, n, </p></blockquote><pre><code class="language-none">                                     tail=&quot;one-sided&quot;,
                                     method=&quot;ly&quot;,
                                     kappa=1.0)</code></pre><blockquote><p>bf10neg = Pingouin.bayesfactor_pearson(r, n,</p></blockquote><pre><code class="language-none">                                     tail=&quot;less&quot;,
                                     method=&quot;ly&quot;,
                                     kappa=1.0)</code></pre><blockquote><p>print(&quot;BF-pos: &quot;, round.(bf10pos, digits=3),&quot; BF-neg: &quot;, round.(bf10neg, digits=3))</p></blockquote><p>BF-pos: 21.185, BF-neg: 0.082</p><p>We can also only pass <span>$tail=&#39;one-sided&#39;$</span> and Pingouin will automatically infer the directionality of the test based on the <span>$r$</span> value.</p><blockquote><p>print(&quot;BF: &quot;, round.(bayesfactor_pearson(r, n, tail=&quot;one-sided&quot;), digits=3))</p></blockquote><p>BF: 21.185</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/anirudhacharya/Pingouin.jl/blob/e0e43de96f2b5e7106e5ce755b0db920e02b9ae9/src/bayesian.jl#L100-L210">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.bayesfactor_ttest" href="#Pingouin.bayesfactor_ttest"><code>Pingouin.bayesfactor_ttest</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Bayes Factor of a T-test.</p><p><strong>Parameters</strong></p><p>t : float     T-value of the T-test nx : int     Sample size of first group ny : int     Sample size of second group (only needed in case of an independent     two-sample T-test) paired : boolean     Specify whether the two observations are related (i.e. repeated     measures) or independent. tail : string     Specify whether the test is <code>&#39;one-sided&#39;</code> or <code>&#39;two-sided&#39;</code>. Can also be     <code>&#39;greater&#39;</code> or <code>&#39;less&#39;</code> to specify the direction of the test.     .. warning:: One-sided Bayes Factor (BF) are simply obtained by         doubling the two-sided BF, which is not exactly the same behavior         as R or JASP. Be extra careful when interpretating one-sided BF,         and if you can, always double-check your results. r : float     Cauchy scale factor. Smaller values of <span>$r$</span> (e.g. 0.5), may be     appropriate when small effect sizes are expected a priori; larger     values of <span>$r$</span> are appropriate when large effect sizes are     expected (Rouder et al 2009). The default is     :math:<code>\sqrt{2} / 2 \approx 0.707</code>.</p><p><strong>Returns</strong></p><p>bf : float     Scaled Jeffrey-Zellner-Siow (JZS) Bayes Factor (BF10).     The Bayes Factor quantifies the evidence in favour of the     alternative hypothesis.</p><p><strong>See also</strong></p><p>ttest : T-test pairwise<em>ttest : Pairwise T-tests bayesfactor</em>pearson : Bayes Factor of a correlation bayesfactor_binom : Bayes Factor of a binomial test</p><p><strong>Notes</strong></p><p>Adapted from a Matlab code found at https://github.com/anne-urai/Tools/tree/master/stats/BayesFactors If you would like to compute the Bayes Factor directly from the raw data instead of from the T-value, use the :py:func:<code>pingouin.ttest</code> function. The JZS Bayes Factor is approximated using the formula described in ref [1]<em>: .. math::     \text{BF}</em>{10} = \frac{\int_{0}^{\infty}(1 + Ngr^2)^{-1/2}     (1 + \frac{t^2}{v(1 + Ngr^2)})^{-(v+1) / 2}(2\pi)^{-1/2}g^     {-3/2}e^{-1/2g}}{(1 + \frac{t^2}{v})^{-(v+1) / 2}} where :math:<code>t</code> is the T-value, :math:<code>v</code> the degrees of freedom, :math:<code>N</code> the sample size, :math:<code>r</code> the Cauchy scale factor (= prior on effect size) and :math:<code>g</code> is is an auxiliary variable that is integrated out numerically. Results have been validated against JASP and the BayesFactor R package.</p><p><strong>References</strong></p><p>.. [1] Rouder, J.N., Speckman, P.L., Sun, D., Morey, R.D., Iverson, G.,</p><ol><li>Bayesian t tests for accepting and rejecting the null hypothesis.</li></ol><p>Psychon. Bull. Rev. 16, 225–237. https://doi.org/10.3758/PBR.16.2.225</p><p><strong>Examples</strong></p><ol><li>Bayes Factor of an independent two-sample T-test</li></ol><blockquote><p>bf = Pingouin.bayesfactor_ttest(3.5, 20, 20) print(&quot;Bayes Factor: &quot;, round.(bf, digits=3), &quot;(two-sample independent)&quot;)</p></blockquote><p>Bayes Factor: 26.743 (two-sample independent)</p><ol><li>Bayes Factor of a paired two-sample T-test</li></ol><blockquote><p>bf = Pingouin.bayesfactor_ttest(3.5, 20, 20, paired=true) print(&quot;Bayes Factor: &quot;, round.(bf, digits=3), &quot;(two-sample paired)&quot;)</p></blockquote><p>Bayes Factor: 17.185 (two-sample paired)</p><ol><li>Bayes Factor of an one-sided one-sample T-test</li></ol><blockquote><p>bf = Pingouin.bayesfactor_ttest(3.5, 20, tail=&quot;one-sided&quot;) print(&quot;Bayes Factor: &quot;, round.(bf, digits=3), &quot;(one-sample)&quot;)</p></blockquote><p>Bayes Factor: 34.369 (one-sample)</p><ol><li>Now specifying the direction of the test</li></ol><blockquote><p>tval = -3.5 bf<em>greater = Pingouin.bayesfactor</em>ttest(tval, 20, tail=&quot;greater&quot;) bf<em>less = Pingouin.bayesfactor</em>ttest(tval, 20, tail=&quot;less&quot;) print(&quot;BF10-greater: &quot;, round.(bf<em>greater, digits=3), &quot; | BF10-less: &quot;, round.(bf</em>less, digits=3))</p></blockquote><p>BF10-greater: 0.029 | BF10-less: 34.369</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/anirudhacharya/Pingouin.jl/blob/e0e43de96f2b5e7106e5ce755b0db920e02b9ae9/src/bayesian.jl#L281-L375">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.list_dataset-Tuple{}" href="#Pingouin.list_dataset-Tuple{}"><code>Pingouin.list_dataset</code></a> — <span class="docstring-category">Method</span></header><section><div><p>List available example datasets.</p><p><strong>Returns</strong></p><p>datasets : <code>DataFrame</code>     A dataframe with the name, description and reference of all the     datasets included in Pingouin.</p><p><strong>Examples</strong></p><blockquote><blockquote><blockquote><p>all<em>datasets = Pingouin.list</em>dataset()</p></blockquote></blockquote></blockquote><p>28×4 DataFrame. Omitted printing of 1 columns │ Row │ dataset    │ description                                                                                                        │ useful                 │ │     │ String     │ String                                                                                                             │ String                 │ ├─────┼────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────┤ │ 1   │ ancova     │ Teaching method with family income as covariate                                                                    │ ANCOVA                 │ │ 2   │ anova      │ Pain threshold per hair color                                                                                      │ anova - pairwise<em>tukey │ │ 3   │ anova2     │ Fertilizer impact on the yield of crops                                                                            │ anova                  │ ⋮ │ 25  │ rm</em>anova2  │ Performance of employees at two time points and three areas                                                        │ rm<em>anova2              │ │ 26  │ rm</em>corr    │ Repeated measurements of pH and PaCO2                                                                              │ rm<em>corr                │ │ 27  │ rm</em>missing │ Missing values in long-format repeated measures dataframe                                                          │ rm<em>anova - rm</em>anova2   │ │ 28  │ tips       │ One waiter recorded information about each tip he received over a period of a few months working in one restaurant │ regression             │</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/anirudhacharya/Pingouin.jl/blob/e0e43de96f2b5e7106e5ce755b0db920e02b9ae9/src/datasets.jl#L48-L73">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.read_dataset-Tuple{String}" href="#Pingouin.read_dataset-Tuple{String}"><code>Pingouin.read_dataset</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Read example datasets.</p><p><strong>Parameters</strong></p><p>dname : string     Name of dataset to read (without extension).     Must be a valid dataset present in pingouin.datasets</p><p><strong>Returns</strong></p><p>data : <code>DataFrame</code>     Requested dataset.</p><p><strong>Examples</strong></p><p>Load the <code>Penguin &lt;https://github.com/allisonhorst/palmerpenguins&gt;</code>_ dataset:</p><blockquote><blockquote><blockquote><p>data = Pingouin.read_dataset(&quot;penguins&quot;)</p></blockquote></blockquote></blockquote><p>344×7 DataFrame │ Row │ species │ island │ bill<em>length</em>mm │ bill<em>depth</em>mm │ flipper<em>length</em>mm │ body<em>mass</em>g │ sex    │ │     │ String  │ String │ String         │ String        │ String            │ String      │ String │ ├─────┼─────────┼────────┼────────────────┼───────────────┼───────────────────┼─────────────┼────────┤ │ 1   │ Adelie  │ Biscoe │ 37.8           │ 18.3          │ 174               │ 3400        │ female │ │ 2   │ Adelie  │ Biscoe │ 37.7           │ 18.7          │ 180               │ 3600        │ male   │ │ 3   │ Adelie  │ Biscoe │ 35.9           │ 19.2          │ 189               │ 3800        │ female │ ⋮ │ 341 │ Gentoo  │ Biscoe │ 46.8           │ 14.3          │ 215               │ 4850        │ female │ │ 342 │ Gentoo  │ Biscoe │ 50.4           │ 15.7          │ 222               │ 5750        │ male   │ │ 343 │ Gentoo  │ Biscoe │ 45.2           │ 14.8          │ 212               │ 5200        │ female │ │ 344 │ Gentoo  │ Biscoe │ 49.9           │ 16.1          │ 213               │ 5400        │ male   │</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/anirudhacharya/Pingouin.jl/blob/e0e43de96f2b5e7106e5ce755b0db920e02b9ae9/src/datasets.jl#L4-L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin._transform_rm-Tuple{DataFrames.DataFrame}" href="#Pingouin._transform_rm-Tuple{DataFrames.DataFrame}"><code>Pingouin._transform_rm</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Convert long-format dataframe (one and two-way designs). This internal function is used in Pingouin.epsilon and Pingouin.sphericity.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/anirudhacharya/Pingouin.jl/blob/e0e43de96f2b5e7106e5ce755b0db920e02b9ae9/src/distributions.jl#L948-L951">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.anderson-Tuple{Array{var&quot;#s31&quot;,N} where N where var&quot;#s31&quot;&lt;:Number}" href="#Pingouin.anderson-Tuple{Array{var&quot;#s31&quot;,N} where N where var&quot;#s31&quot;&lt;:Number}"><code>Pingouin.anderson</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Anderson-Darling test of distribution.</p><p><strong>Parameters</strong></p><p>sample1, sample2,... : array_like     Array of sample data. May be different lengths. dist : Union{String, Distribution}     Distribution (&quot;norm&quot;, &quot;expon&quot;, &quot;logistic&quot;, &quot;gumbel&quot;)</p><p><strong>Returns</strong></p><p>H : boolean     True if data comes from this distribution. P : float     The significance levels for the corresponding critical values in %.     (See :<code>HypothesisTests.OneSampleADTest</code> for more details)</p><p><strong>Examples</strong></p><ol><li>Test that an array comes from a normal distribution</li></ol><blockquote><blockquote><blockquote><p>x = [2.3, 5.1, 4.3, 2.6, 7.8, 9.2, 1.4] Pingouin.anderson(x, dist=&quot;norm&quot;)</p></blockquote></blockquote></blockquote><p>(false, 8.571428568870942e-5)</p><ol><li>Test that an array comes from a custom distribution</li></ol><blockquote><blockquote><blockquote><p>x = [2.3, 5.1, 4.3, 2.6, 7.8, 9.2, 1.4] Pingouin.anderson(x, dist=Normal(1,5))</p></blockquote></blockquote></blockquote><p>(false, 0.04755873570126501)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/anirudhacharya/Pingouin.jl/blob/e0e43de96f2b5e7106e5ce755b0db920e02b9ae9/src/distributions.jl#L68-L99">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.epsilon-Tuple{Union{DataFrames.DataFrame, Array{var&quot;#s30&quot;,N} where N where var&quot;#s30&quot;&lt;:Number}}" href="#Pingouin.epsilon-Tuple{Union{DataFrames.DataFrame, Array{var&quot;#s30&quot;,N} where N where var&quot;#s30&quot;&lt;:Number}}"><code>Pingouin.epsilon</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Epsilon adjustement factor for repeated measures.</p><p><strong>Parameters</strong></p><p>data : <code>DataFrame</code>     DataFrame containing the repeated measurements.     Only long-format dataframe are supported for this function. dv : string     Name of column containing the dependent variable. within : string     Name of column containing the within factor (only required if <span>$data$</span>     is in long format).     If <span>$within$</span> is a list with two strings, this function computes     the epsilon factor for the interaction between the two within-subject     factor. subject : string     Name of column containing the subject identifier (only required if     <span>$data$</span> is in long format). correction : string     Specify the epsilon version:</p><pre><code class="language-none">* ``&quot;gg&quot;``: Greenhouse-Geisser
* ``&quot;hf&quot;``: Huynh-Feldt
* ``&quot;lb&quot;``: Lower bound</code></pre><p><strong>Returns</strong></p><p>eps : float     Epsilon adjustement factor.</p><p><strong>See Also</strong></p><p>sphericity : Mauchly and JNS test for sphericity. homoscedasticity : Test equality of variance.</p><p><strong>Notes</strong></p><p>The lower bound epsilon is:</p><p>.. math:: lb = \frac{1}{\text{dof}},</p><p>where the degrees of freedom :math:<code>\text{dof}</code> is the number of groups :math:<code>k</code> minus 1 for one-way design and :math:<code>(k_1 - 1)(k_2 - 1)</code> for two-way design</p><p>The Greenhouse-Geisser epsilon is given by:</p><p>.. math::</p><pre><code class="language-none">\epsilon_{GG} = \frac{k^2(\overline{\text{diag}(S)} -
\overline{S})^2}{(k-1)(\sum_{i=1}^{k}\sum_{j=1}^{k}s_{ij}^2 -
2k\sum_{j=1}^{k}\overline{s_i}^2 + k^2\overline{S}^2)}</code></pre><p>where :math:<code>S</code> is the covariance matrix, :math:<code>\overline{S}</code> the grandmean of S and :math:<code>\overline{\text{diag}(S)}</code> the mean of all the elements on the diagonal of S (i.e. mean of the variances).</p><p>The Huynh-Feldt epsilon is given by:</p><p>.. math::</p><pre><code class="language-none">\epsilon_{HF} = \frac{n(k-1)\epsilon_{GG}-2}{(k-1)
(n-1-(k-1)\epsilon_{GG})}</code></pre><p>where :math:<code>n</code> is the number of observations.</p><p>Missing values are automatically removed from data (listwise deletion).</p><p><strong>Examples</strong></p><p>Using a wide-format dataframe</p><blockquote><blockquote><blockquote><p>data = DataFrame(A = [2.2, 3.1, 4.3, 4.1, 7.2],</p></blockquote></blockquote></blockquote><pre><code class="language-none">                 B = [1.1, 2.5, 4.1, 5.2, 6.4],
                 C = [8.2, 4.5, 3.4, 6.2, 7.2])</code></pre><blockquote><blockquote><blockquote><p>Pingouin.epsilon(data, correction=&quot;gg&quot;)</p></blockquote></blockquote></blockquote><p>0.5587754577585018</p><blockquote><blockquote><blockquote><p>Pingouin.epsilon(data, correction=&quot;hf&quot;)</p></blockquote></blockquote></blockquote><p>0.6223448311539789</p><blockquote><blockquote><blockquote><p>Pingouin.epsilon(data, correction=&quot;lb&quot;)</p></blockquote></blockquote></blockquote><p>0.5</p><p>Now using a long-format dataframe</p><blockquote><blockquote><blockquote><p>data = Pingouin.read<em>dataset(&quot;rm</em>anova2&quot;) head(data)</p></blockquote></blockquote></blockquote><p>6×4 DataFrame │ Row │ Subject │ Time   │ Metric  │ Performance │ │     │ Int64   │ String │ String  │ Int64       │ ├─────┼─────────┼────────┼─────────┼─────────────┤ │ 1   │ 1       │ Pre    │ Product │ 13          │ │ 2   │ 2       │ Pre    │ Product │ 12          │ │ 3   │ 3       │ Pre    │ Product │ 17          │ │ 4   │ 4       │ Pre    │ Product │ 12          │ │ 5   │ 5       │ Pre    │ Product │ 19          │ │ 6   │ 6       │ Pre    │ Product │ 6           │</p><p>Let&#39;s first calculate the epsilon of the <em>Time</em> within-subject factor</p><blockquote><blockquote><blockquote><p>Pingouin.epsilon(data, dv=&quot;Performance&quot;, subject=&quot;Subject&quot;,</p></blockquote></blockquote></blockquote><pre><code class="language-none">                 within=&quot;Time&quot;)</code></pre><p>1.0</p><p>Since <em>Time</em> has only two levels (Pre and Post), the sphericity assumption is necessarily met, and therefore the epsilon adjustement factor is 1.</p><p>The <em>Metric</em> factor, however, has three levels:</p><blockquote><blockquote><blockquote><p>Pingouin.epsilon(data, dv=:Performance, subject=:Subject,</p></blockquote></blockquote></blockquote><pre><code class="language-none">                 within=[:Metric])</code></pre><p>0.9691029584899762</p><p>The epsilon value is very close to 1, meaning that there is no major violation of sphericity.</p><p>Now, let&#39;s calculate the epsilon for the interaction between the two repeated measures factor:</p><blockquote><blockquote><blockquote><p>Pingouin.epsilon(data, dv=:Performance, subject=:Subject,</p></blockquote></blockquote></blockquote><pre><code class="language-none">                 within=[:Time, :Metric])</code></pre><p>0.727166420214127</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/anirudhacharya/Pingouin.jl/blob/e0e43de96f2b5e7106e5ce755b0db920e02b9ae9/src/distributions.jl#L764-L886">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.gzscore-Tuple{Array{var&quot;#s33&quot;,N} where N where var&quot;#s33&quot;&lt;:Number}" href="#Pingouin.gzscore-Tuple{Array{var&quot;#s33&quot;,N} where N where var&quot;#s33&quot;&lt;:Number}"><code>Pingouin.gzscore</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Geometric standard (Z) score.</p><p><strong>Parameters</strong></p><p>x : array_like     Array of raw values</p><p><strong>Returns</strong></p><p>gzscore : array_like     Array of geometric z-scores (same shape as x)</p><p><strong>Notes</strong></p><p>Geometric Z-scores are better measures of dispersion than arithmetic z-scores when the sample data come from a log-normally distributed population [1]_.</p><p>Given the raw scores :math:<code>x</code>, the geometric mean :math:<code>\mu_g</code> and the geometric standard deviation :math:<code>\sigma_g</code>, the standard score is given by the formula:</p><p>.. math:: z = \frac{log(x) - log(\mu<em>g)}{log(\sigma</em>g)}</p><p><strong>References</strong></p><p>.. [1] https://en.wikipedia.org/wiki/Geometric<em>standard</em>deviation</p><p><strong>Examples</strong></p><p>Standardize a lognormal-distributed vector:</p><blockquote><blockquote><blockquote><p>raw = [1,4,5,4,1,2,5,8,6,6,9,8,3] z = Pingouin.gzscore(raw)</p></blockquote></blockquote></blockquote><p>13-element Array{Float64,1}:  -1.8599725059104346   0.03137685347921089   0.3358161014965816   0.03137685347921089  -1.8599725059104346   ⋮   0.5845610789821727   0.5845610789821727   1.1377453044851344   0.9770515331740336  -0.3611136007126501</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/anirudhacharya/Pingouin.jl/blob/e0e43de96f2b5e7106e5ce755b0db920e02b9ae9/src/distributions.jl#L10-L57">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.homoscedasticity-Tuple{Any}" href="#Pingouin.homoscedasticity-Tuple{Any}"><code>Pingouin.homoscedasticity</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Test equality of variance.</p><pre><code class="language-none">Parameters
----------
data : `DataFrame` or array
    Iterable. Can be either an Array iterables or a wide- or long-format
    pandas dataframe.
dv : str
    Dependent variable (only when ``data`` is a long-format dataframe).
group : str
    Grouping variable (only when ``data`` is a long-format dataframe).
method : str
    Statistical test. `&#39;levene&#39;` (default) performs the Levene test
    and `&#39;bartlett&#39;` performs the Bartlett test.
    The former is more robust to departure from normality.
alpha : float
    Significance level.

Returns
-------
stats : `DataFrame`

    * ``&#39;W/T&#39;``: Test statistic (&#39;W&#39; for Levene, &#39;T&#39; for Bartlett)
    * ``&#39;pval&#39;``: p-value
    * ``&#39;equal_var&#39;``: True if ``data`` has equal variance

See Also
--------
normality : Univariate normality test.
sphericity : Mauchly&#39;s test for sphericity.

Notes
-----
The **Bartlett** :math:`T` statistic [1]_ is defined as:

.. math::

    T = \frac{(N-k) \ln{s^{2}_{p}} - \sum_{i=1}^{k}(N_{i} - 1)
    \ln{s^{2}_{i}}}{1 + (1/(3(k-1)))((\sum_{i=1}^{k}{1/(N_{i} - 1))}
    - 1/(N-k))}

where :math:`s_i^2` is the variance of the :math:`i^{th}` group,
:math:`N` is the total sample size, :math:`N_i` is the sample size of the
:math:`i^{th}` group, :math:`k` is the number of groups,
and :math:`s_p^2` is the pooled variance.

The pooled variance is a weighted average of the group variances and is
defined as:

.. math:: s^{2}_{p} = \sum_{i=1}^{k}(N_{i} - 1)s^{2}_{i}/(N-k)

The p-value is then computed using a chi-square distribution:

.. math:: T \sim \chi^2(k-1)

The **Levene** :math:`W` statistic [2]_ is defined as:

.. math::

    W = \frac{(N-k)} {(k-1)}
    \frac{\sum_{i=1}^{k}N_{i}(\overline{Z}_{i.}-\overline{Z})^{2} }
    {\sum_{i=1}^{k}\sum_{j=1}^{N_i}(Z_{ij}-\overline{Z}_{i.})^{2} }

where :math:`Z_{ij} = |Y_{ij} - \text{median}({Y}_{i.})|`,
:math:`\overline{Z}_{i.}` are the group means of :math:`Z_{ij}` and
:math:`\overline{Z}` is the grand mean of :math:`Z_{ij}`.

The p-value is then computed using a F-distribution:

.. math:: W \sim F(k-1, N-k)

.. warning:: Missing values are not supported for this function.
    Make sure to remove them before using the
    :py:meth:`pandas.DataFrame.dropna` or :py:func:`pingouin.remove_na`
    functions.

References
----------
.. [1] Bartlett, M. S. (1937). Properties of sufficiency and statistical
       tests. Proc. R. Soc. Lond. A, 160(901), 268-282.

.. [2] Brown, M. B., &amp; Forsythe, A. B. (1974). Robust tests for the
       equality of variances. Journal of the American Statistical
       Association, 69(346), 364-367.

Examples
--------
1. Levene test on a wide-format dataframe

&gt;&gt;&gt; data = Pingouin.read_dataset(&quot;mediation&quot;)
&gt;&gt;&gt; Pingouin.homoscedasticity(data[[&quot;X&quot;, &quot;Y&quot;, &quot;M&quot;]])
1×3 DataFrame
│ Row │ W       │ pval     │ equal_var │
│     │ Float64 │ Float64  │ Bool      │
├─────┼─────────┼──────────┼───────────┤
│ 1   │ 1.17352 │ 0.310707 │ 1         │

2. Bartlett test using an array of arrays

&gt;&gt;&gt; data = [[4, 8, 9, 20, 14], [5, 8, 15, 45, 12]]
&gt;&gt;&gt; Pingouin.homoscedasticity(data, method=&quot;bartlett&quot;, α=.05)
1×3 DataFrame
│ Row │ T       │ pval     │ equal_var │
│     │ Float64 │ Float64  │ Bool      │
├─────┼─────────┼──────────┼───────────┤
│ 1   │ 2.87357 │ 0.090045 │ 1         │

3. Long-format dataframe

&gt;&gt;&gt; data = Pingouin.read_dataset(&quot;rm_anova2&quot;)
&gt;&gt;&gt; Pingouin.homoscedasticity(data, dv=&quot;Performance&quot;, group=&quot;Time&quot;)
1×3 DataFrame
│ Row │ W       │ pval      │ equal_var │
│     │ Float64 │ Float64   │ Bool      │
├─────┼─────────┼───────────┼───────────┤
│ 1   │ 3.1922  │ 0.0792169 │ 1         │</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/anirudhacharya/Pingouin.jl/blob/e0e43de96f2b5e7106e5ce755b0db920e02b9ae9/src/distributions.jl#L322-L439">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.jarque_bera" href="#Pingouin.jarque_bera"><code>Pingouin.jarque_bera</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Compute the Jarque-Bera statistic to test the null hypothesis that a real-valued vector <code>y</code> is normally distributed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/anirudhacharya/Pingouin.jl/blob/e0e43de96f2b5e7106e5ce755b0db920e02b9ae9/src/distributions.jl#L309-L311">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.normality-Tuple{Any}" href="#Pingouin.normality-Tuple{Any}"><code>Pingouin.normality</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Univariate normality test.</p><pre><code class="language-none">Parameters
----------
data : `DataFrame`, series, list or 1D array
    Iterable. Can be either a single list, 1D array,
    or a wide- or long-format dataframe.
dv : str
    Dependent variable (only when ``data`` is a long-format dataframe).
group : str
    Grouping variable (only when ``data`` is a long-format dataframe).
method : str
    Normality test. `&#39;shapiro&#39;` (default) performs the Shapiro-Wilk test
    using the AS R94 algorithm. If the kurtosis is higher than 3, it 
    performs a Shapiro-Francia test for leptokurtic distributions.
    Supported values: [&quot;shapiro&quot;, &quot;jarque_bera&quot;].
alpha : float64
    Significance level.

Returns
-------
stats : `DataFrame`

    * ``&#39;W&#39;``: Test statistic.
    * ``&#39;pval&#39;``: p-value.
    * ``&#39;normal&#39;``: True if ``data`` is normally distributed.

See Also
--------
homoscedasticity : Test equality of variance.
sphericity : Mauchly&#39;s test for sphericity.

Notes
-----
The Shapiro-Wilk test calculates a :math:`W` statistic that tests whether a
random sample :math:`x_1, x_2, ..., x_n` comes from a normal distribution.

The :math:`W` is normalized (:math:`W = (W - μ) / σ`)

The null-hypothesis of this test is that the population is normally
distributed. Thus, if the p-value is less than the
chosen alpha level (typically set at 0.05), then the null hypothesis is
rejected and there is evidence that the data tested are not normally
distributed.

The result of the Shapiro-Wilk test should be interpreted with caution in
the case of large sample sizes (&gt;5000). Indeed, quoting from
`Wikipedia &lt;https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test&gt;`_:

    *&quot;Like most statistical significance tests, if the sample size is
    sufficiently large this test may detect even trivial departures from
    the null hypothesis (i.e., although there may be some statistically
    significant effect, it may be too small to be of any practical
    significance); thus, additional investigation of the effect size is
    typically advisable, e.g., a Q–Q plot in this case.&quot;*

The Jarque-Bera statistic is to test the null hypothesis that a real-valued vector `y`
is normally distributed. Note that the approximation by the Chi-squared distribution does
not work well and the speed of convergence is slow.
In small samples, the test tends to be over-sized for nominal levels up to about 3% and
under-sized for larger nominal levels (Mantalos, 2010).

Note that missing values are automatically removed (casewise deletion).

References
----------
* Shapiro, S. S., &amp; Wilk, M. B. (1965). An analysis of variance test
for normality (complete samples). Biometrika, 52(3/4), 591-611.

* Panagiotis Mantalos, 2011, &quot;The three different measures of the sample skewness and
kurtosis and the effects to the Jarque-Bera test for normality&quot;, International Journal
of Computational Economics and Econometrics, Vol. 2, No. 1,
[link](http://dx.doi.org/10.1504/IJCEE.2011.040576).

* https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm

* [Jarque-Bera test on Wikipedia](https://en.wikipedia.org/wiki/Jarque–Bera_test)

Examples
--------
1. Shapiro-Wilk test on a 1D array
&gt;&gt;&gt; dataset = Pingouin.read_dataset(&quot;anova&quot;)
&gt;&gt;&gt; Pingouin.normality(dataset[&quot;Pain threshold&quot;])
1×3 DataFrame
│ Row │ W         │ pval     │ normal │
│     │ Float64   │ Float64  │ Bool   │
├─────┼───────────┼──────────┼────────┤
│ 1   │ -0.842541 │ 0.800257 │ 1      │

2. Wide-format dataframe using Jarque-Bera test

&gt;&gt;&gt; dataset = Pingouin.read_dataset(&quot;mediation&quot;)
&gt;&gt;&gt; Pingouin.normality(dataset, method=&quot;jarque_bera&quot;)
│ Row │ dv     │ W        │ pval        │ normal │
│     │ Symbol │ Float64  │ Float64     │ Bool   │
├─────┼────────┼──────────┼─────────────┼────────┤
│ 1   │ X      │ 1.42418  │ 0.490618    │ 1      │
│ 2   │ M      │ 0.645823 │ 0.724038    │ 1      │
│ 3   │ Y      │ 0.261805 │ 0.877303    │ 1      │
│ 4   │ Mbin   │ 16.6735  │ 0.000239553 │ 0      │
│ 5   │ Ybin   │ 16.6675  │ 0.000240265 │ 0      │
│ 6   │ W1     │ 5.40923  │ 0.0668961   │ 1      │
│ 7   │ W2     │ 80.6857  │ 3.01529e-18 │ 0      │

3. Long-format dataframe

&gt;&gt;&gt; dataset = Pingouin.read_dataset(&quot;rm_anova2&quot;)
&gt;&gt;&gt; Pingouin.normality(dataset, dv=:Performance, group=:Time)
│ Row │ Time   │ W         │ pval      │ normal │
│     │ String │ Float64   │ Float64   │ Bool   │
├─────┼────────┼───────────┼───────────┼────────┤
│ 1   │ Pre    │ 0.0532374 │ 0.478771  │ 1      │
│ 2   │ Post   │ 1.30965   │ 0.0951576 │ 1      │</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/anirudhacharya/Pingouin.jl/blob/e0e43de96f2b5e7106e5ce755b0db920e02b9ae9/src/distributions.jl#L124-L239">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.shapiro" href="#Pingouin.shapiro"><code>Pingouin.shapiro</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Compute the Shapiro-Wilk statistic to test the null hypothesis that a real-valued vector <code>y</code> is normally distributed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/anirudhacharya/Pingouin.jl/blob/e0e43de96f2b5e7106e5ce755b0db920e02b9ae9/src/distributions.jl#L284-L286">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Pingouin.sphericity-Tuple{DataFrames.DataFrame}" href="#Pingouin.sphericity-Tuple{DataFrames.DataFrame}"><code>Pingouin.sphericity</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Mauchly and JNS test for sphericity.</p><p><strong>Parameters</strong></p><p>data : <code>DataFrame</code>     DataFrame containing the repeated measurements.     Only long-format dataframe are supported for this function. dv : string     Name of column containing the dependent variable. within : string     Name of column containing the within factor.     If <span>$within$</span> is a list with two strings, this function computes     the epsilon factor for the interaction between the two within-subject     factor. subject : string     Name of column containing the subject identifier (only required if     <span>$data$</span> is in long format). method : str     Method to compute sphericity:</p><pre><code class="language-none">* `&#39;jns&#39;`: John, Nagao and Sugiura test.
* `&#39;mauchly&#39;`: Mauchly test (default).</code></pre><p>alpha : float     Significance level</p><p><strong>Returns</strong></p><p>spher : boolean     True if data have the sphericity property. W : float     Test statistic. chi2 : float     Chi-square statistic. dof : int     Degrees of freedom. pval : float     P-value.</p><p><strong>Raises</strong></p><p>ValueError     When testing for an interaction, if both within-subject factors have     more than 2 levels (not yet supported in Pingouin).</p><p><strong>See Also</strong></p><p>epsilon : Epsilon adjustement factor for repeated measures. homoscedasticity : Test equality of variance. normality : Univariate normality test.</p><p><strong>Notes</strong></p><p>The <strong>Mauchly</strong> :math:<code>W</code> statistic [1]_ is defined by:</p><p>.. math::</p><pre><code class="language-none">W = \frac{\prod \lambda_j}{(\frac{1}{k-1} \sum \lambda_j)^{k-1}}</code></pre><p>where :math:<code>\lambda_j</code> are the eigenvalues of the population covariance matrix (= double-centered sample covariance matrix) and :math:<code>k</code> is the number of conditions.</p><p>From then, the :math:<code>W</code> statistic is transformed into a chi-square score using the number of observations per condition :math:<code>n</code></p><p>.. math:: f = \frac{2(k-1)^2+k+1}{6(k-1)(n-1)} .. math:: \chi_w^2 = (f-1)(n-1) \text{log}(W)</p><p>The p-value is then approximated using a chi-square distribution:</p><p>.. math:: \chi_w^2 \sim \chi^2(\frac{k(k-1)}{2}-1)</p><p>The <strong>JNS</strong> :math:<code>V</code> statistic ([2]<em>, [3]</em>, [4]_) is defined by:</p><p>.. math::</p><pre><code class="language-none">V = \frac{(\sum_j^{k-1} \lambda_j)^2}{\sum_j^{k-1} \lambda_j^2}</code></pre><p>.. math:: \chi_v^2 = \frac{n}{2}  (k-1)^2 (V - \frac{1}{k-1})</p><p>and the p-value approximated using a chi-square distribution</p><p>.. math:: \chi_v^2 \sim \chi^2(\frac{k(k-1)}{2}-1)</p><p>Missing values are automatically removed from <span>$data$</span> (listwise deletion).</p><p><strong>References</strong></p><p>.. [1] Mauchly, J. W. (1940). Significance test for sphericity of a normal        n-variate distribution. The Annals of Mathematical Statistics,        11(2), 204-209.</p><p>.. [2] Nagao, H. (1973). On some test criteria for covariance matrix.        The Annals of Statistics, 700-709.</p><p>.. [3] Sugiura, N. (1972). Locally best invariant test for sphericity and        the limiting distributions. The Annals of Mathematical Statistics,        1312-1316.</p><p>.. [4] John, S. (1972). The distribution of a statistic used for testing        sphericity of normal distributions. Biometrika, 59(1), 169-173.</p><p>See also http://www.real-statistics.com/anova-repeated-measures/sphericity/</p><p><strong>Examples</strong></p><p>Mauchly test for sphericity using a wide-format dataframe</p><blockquote><blockquote><blockquote><p>data = DataFrame(A = [2.2, 3.1, 4.3, 4.1, 7.2],</p></blockquote></blockquote></blockquote><pre><code class="language-none">                 B = [1.1, 2.5, 4.1, 5.2, 6.4],
                 C = [8.2, 4.5, 3.4, 6.2, 7.2])</code></pre><blockquote><blockquote><blockquote><p>Pingouin.sphericity(data)</p></blockquote></blockquote></blockquote><p>│ Row │ spher │ W        │ chi2    │ dof     │ pval      │ │     │ Bool  │ Float64  │ Float64 │ Float64 │ Float64   │ ├─────┼───────┼──────────┼─────────┼─────────┼───────────┤ │ 1   │ 1     │ 0.210372 │ 4.67663 │ 2.0     │ 0.0964902 │</p><p>John, Nagao and Sugiura (JNS) test</p><blockquote><blockquote><blockquote><p>Pingouin.sphericity(data, method=&quot;jns&quot;)[:pval]  # P-value only</p></blockquote></blockquote></blockquote><p>0.045604240307520305</p><p>Now using a long-format dataframe</p><blockquote><blockquote><blockquote><p>data = Pingouin.read<em>dataset(&quot;rm</em>anova2&quot;) head(data)</p></blockquote></blockquote></blockquote><p>6x4 DataFrame │ Row │ Subject │ Time   │ Metric  │ Performance │ │     │ Int64   │ String │ String  │ Int64       │ ├─────┼─────────┼────────┼─────────┼─────────────┤ │ 1   │ 1       │ Pre    │ Product │ 13          │ │ 2   │ 2       │ Pre    │ Product │ 12          │ │ 3   │ 3       │ Pre    │ Product │ 17          │ │ 4   │ 4       │ Pre    │ Product │ 12          │ │ 5   │ 5       │ Pre    │ Product │ 19          │ │ 6   │ 6       │ Pre    │ Product │ 6           │</p><p>Let&#39;s first test sphericity for the <em>Time</em> within-subject factor</p><blockquote><blockquote><blockquote><p>Pingouin.sphericity(data, dv=:Performance, subject=:Subject,</p></blockquote></blockquote></blockquote><pre><code class="language-none">                    within=:Time)</code></pre><p>│ Row │ spher │ W       │ chi2    │ dof   │ pval    │ │     │ Bool  │ Float64 │ Float64 │ Int64 │ Float64 │ ├─────┼───────┼─────────┼─────────┼───────┼─────────┤ │ 1   │ 1     │ NaN     │ NaN     │ 1     │ 1.0     │</p><p>Since <em>Time</em> has only two levels (Pre and Post), the sphericity assumption is necessarily met.</p><p>The <em>Metric</em> factor, however, has three levels:</p><blockquote><blockquote><blockquote><p>Pingouin.sphericity(data, dv=&quot;Performance&quot;, subject=&quot;Subject&quot;,</p></blockquote></blockquote></blockquote><pre><code class="language-none">                    within=[&quot;Metric&quot;])[:pval]</code></pre><p>0.8784417991645139</p><p>The p-value value is very large, and the test therefore indicates that there is no violation of sphericity.</p><p>Now, let&#39;s calculate the epsilon for the interaction between the two repeated measures factor. The current implementation in Pingouin only works if at least one of the two within-subject factors has no more than two levels.</p><blockquote><blockquote><blockquote><p>Pingouin.sphericity(data, dv=&quot;Performance&quot;,</p></blockquote></blockquote></blockquote><pre><code class="language-none">                    subject=&quot;Subject&quot;,
                    within=[&quot;Time&quot;, &quot;Metric&quot;])</code></pre><p>│ Row │ spher │ W        │ chi2    │ dof     │ pval     │ │     │ Bool  │ Float64  │ Float64 │ Float64 │ Float64  │ ├─────┼───────┼──────────┼─────────┼─────────┼──────────┤ │ 1   │ 1     │ 0.624799 │ 3.7626  │ 2.0     │ 0.152392 │</p><p>Here again, there is no violation of sphericity acccording to Mauchly&#39;s test.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/anirudhacharya/Pingouin.jl/blob/e0e43de96f2b5e7106e5ce755b0db920e02b9ae9/src/distributions.jl#L502-L677">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 19 October 2020 12:58">Monday 19 October 2020</span>. Using Julia version 1.5.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
